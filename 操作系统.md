- 网课（王道操作系统）（共84节）：1、2、3、4、5、6、7、8、**9**、10、11、12、13、14、15、16、17、18、19、20、21、22、23、24、25、26、27、28、29、30、31、32、33、34、35、36、37、38、39、40、41、42、43、44、45、46、47、48、49、50、51、52、53、54、55、56、57、58、59、...、**70**、...、**84**

# 一.操作系统概述

## （一）.操作系统的概念、功能和目标

### 1.操作系统的概念

- 操作系统（Operating System，OS）：是指控制和管理整个计算机系统的硬件和软件资源，并合理地组织调度计算机的工作和资源的分配；以提供给用户和其他软件方便的接口和环境；它是计算机系统中最基本的系统软件。
  - 操作系统是系统资源的管理者
  - 向上层提供方便易用的服务
  - 是最接近硬件的一层软件

### 2.操作系统的功能和目标

#### （1）作为系统资源的管理者

- 提供的功能：
  - 处理机管理
  - 存储管理
  - 文件管理
  - 设备管理
- 目标：
  - 安全
  - 高效
- 补充：执行一个程序前需要将该程序放到内存中，才能被CPU处理

#### （2）向上层提供方便易用的服务

- 封装思想：操作系统把一些丑陋的硬件功能封装成一个简单易用的服务，使用户能更方便地使用计算机，用户无需关心底层硬件的原理，只需要对操作系统发出命令即可
- 直接给用户使用的：
  - GUI：图形化用户接口
    - 如：Windows、安卓、ios的图形化操作页面

  - 命令接口：

    - 联机命令接口（交互式命令接口）
      - 特点：用户说一句，系统做一句

    - 脱机命令接口（批处理命令接口）
      - 特点：用户说一堆，系统做一堆

- 给软件/给程序员使用的：
  - 程序接口（系统调用）：可以在程序中进行系统调用来使用程序接口。普通用户不能直接使用程序接口，只能通过程序代码间接使用


#### （3）作为最接近硬件的层次

- 需要实现对硬件机器的拓展
- 没有任何软件支持的计算机成为裸机。在裸机上安装操作系统，可以提供资源管理功能和方便用户的服务功能，将裸机改造成功能更强。使用更方便的机器
- 通常把覆盖了软件的机器称为扩充机器，又称虚拟机
- 操作系统对硬件机器的拓展，将CPU、内存、磁盘、显示器、键盘等硬件合理的组织起来，让各种硬件能够相互协调配合，实现更多更复杂的功能

## （二）操作系统的特征

- 操作系统的四个特征：
  1. 并发
  2. 共享
  3. 虚拟
  4. 异步
- 并发和共享为两个最基本的特征，二者互为存在条件
- 重点理解：
  - 并发和并行的区别
  - 并发和共享互为存在条件
  - 并发和共享为两个最基本的特征，没有并发和共享就谈不上虚拟和异步

### 1.并发

- 并发：指两个或多个事件在同一时间间隔内发生。这些事件宏观上是同时发生的，但在微观上是交替发生的。
- 并行：指两个或多个事件在同一时刻同时发生
- 操作系统的并发性：计算机系统中“同时”运行着多个程序，这些程序宏观上看是同时运行着，而微观上看是交替运行的
  - 操作系统就是伴随着“多道程序技术”而出现的。因此，操作系统和程序并发是一起诞生的
  - 注意：
    - 单核CPU同一时刻只能执行一个程序，各个程序之间只能并发执行
    - 多核CPU同一时刻可以同时执行，多个程序可以并行执行
- 并发性是操作系统一个最基本的特性

### 2.共享

- 共享：即资源共享，指系统中的资源可供内存中多个并发执行的过程共同使用
- 两种资源共享方式：
  - 互斥共享方式：系统中的某些资源，虽然可以提供给多个进程使用，但一个时间段内只允许一个进程访问该资源
  - 同时共享方式：系统中的某些资源，允许一个时间段内由多个进程“同时”对它们进行访问
    - 所谓的“同时”往往是宏观上的，而在微观上，这些进程可能是交替地对该资源进行访问的（即分时共享）

### 并发和共享的关系

- 并发性和共享性互为存在条件
- 若失去其中一个特性，则另一个特性则失去意义

### 3.虚拟

- 虚拟：指把一个物理上的实体变为若干个逻辑上的对应物。物理实体是实际存在的，而逻辑上对应物是用户感受到的。
  - 问题：多个程序同时运行时所需的内存远大于电脑内存，为什么还可以正常运行？
    - 答：虚拟存储技术，空分复用技术（第三章）。实际只有4GB的内存，在用户看来远远大于4GB
  - 问题：一个程序需要被分配CPU才能正常执行，为什么单核CPU的电脑中能同时运行多个程序呢？
    - 答：虚拟处理器技术，时分复用技术。微观上处理机在各个微小的时间段内交替为各个进程服务。实际上只有一个单核CPU，但在用户看来似乎有多个CPU在同时工作
- 虚拟技术：
  - 空分复用技术（如：虚拟存储技术）
  - 时分复用技术（如：虚拟处理机技术）
    - 如果失去并发性，则一个时间段内只需运行一道程序，那么就失去了虚拟性的意义。因此，没有并发性，就谈不上虚拟性

### 4.异步

- 异步：在多道程序下，允许多个程序并发执行，但由于资源有限，进程的执行不是一贯到底的，而是走走停停，以不可预知的速度向前推进，这就是进程的异步性。
- 如果系统失去了并发性，即系统只能串行地运行各个程序，那么每个程序的执行才会一贯到底。只有系统拥有并发性，才有可能导致异步性

## （三）操作系统的发展和分类

- 重点：关注和理解各类操作系统主要想解决的是什么问题，各自的优缺点

### 1.手工操作阶段

- 主要缺点：用户独占全机，人机速度矛盾导致资源利用率极低

### 2.批处理阶段

- 单道批处理系统：
  - 引入脱机输入/输出技术（由外围机+磁盘完成），并由监督程序负责程序控制作业的输入、输出
  - 主要优点：缓解了一定程度的人机速度矛盾，资源利用率有所提升。
  - 主要缺点：内存中仅能有一道程序运行，只有该程序运行结束之后才能调入下一道程序。CPU有大量的时间是在空闲等待IO完成。资源利用率仍然很低
- 多道批处理系统：
  - 每次往内存中读入多道程序，操作系统正式诞生，用于支持多道程序并发进行
  - 主要优点：多道程序并发执行，共享计算机资源。资源利用率大幅提升，CPU和其他资源更能保持忙碌状态，系统吞吐量增大
  - 主要缺点：用户响应时间长，没有人机交互功能（用户提交自己的作业之后就只能等待计算机处理完成，中间不能控制自己的作业执行。例：无法调试程序，无法在程序运行过程中输入一些参数）

### 3.分时操作系统

- 计算机会以时间片为单位轮流为各个用户/作业服务，各个用户可通过终端与计算机进行交互。
- 主要优点：用户请求可以被及时响应，解决了人机交互问题。允许多个用户同时使用一台计算机，并且用户对计算机的操作相互独立，感受不到别人的存在。
- 主要缺点：不能优先处理一些紧急任务。操作系统对各个用户/作业都是完全公平的，循环地为各个用户/作业服务一个时间片，不区分任务的紧急性

### 4.实时操作系统

- 主要优点：能够优先响应一些紧急任务，某些紧急任务不需时间片排队。
- 在实时操作系统的控制下，计算机系统接收到外部信号后及时处理，并且要在严格的时限内处理完事件。实时操作系统的主要特点是及时性和可靠性
- 实时操作系统：
  - 硬实时系统：必须在绝对严格的规定时间内完成处理
  - 软实时系统：能够接受偶尔违反时间规定

### 5.其他几种操作系统

- 网络操作系统：是伴随着计算机网络的发展而诞生的，能把网络中各个计算机有机地结合起来。实现数据传送等功能，实现网络中各种资源的共享和各台计算机之间的通信。
- 分布式操作系统：主要特点是分布性和并行性。系统中的各台计算机地位相同，任何工作都可以分布在这些计算机上，由它们并行、协同完成这个任务。
- 个人计算机操作系统：windows、macos

## （四）操作系统的运行机制

- 总览：
  - 两种指令：
    - 特权指令
    - 非特权指令

  - 两种处理器状态：
    - 核心态
    - 用户态

  - 两种程序：
    - 内核程序
    - 应用程序

- 指令：就是处理器（CPU）能识别、执行的最基本命令
- 很多内核程序组成“操作系统内核”，简称“内核”。内核是操作系统最重要最核心的部分，也是最接近硬件的部分
  - 应用程序只能使用“非特权指令”，如：加法指令、减法指令等
  - 操作系统内核作为管理者，如：内存清零指令。这些指令影响重大，只允许操作系统内核使用

- 在CPU设计和生产时就划分了特权指令和非特权指令，因此CPU在执行一条指令前就能判断出其类型
- CPU有两种状态：
  - 内核态：处于内核态时，说明此时正在运行的时内核程序，此时可以执行特权指令
    - 内核态，又名核心态、管态

  - 用户态：处于用户态时，说明此时正在运行的是应用程序，此时只能执行非特权指令
    - 用户态，又名目态

- 拓展：CPU中有一个寄存器叫程序状态字寄存器（PSW），其中有个二进制位，1表示内核态，2表示用户态
- 内核态、用户态的切换：
  - 内核态切换为用户态：执行一条特权指令，修改PSW的标志位为用户态，这个动作意味着操作系统将主动让出CPU使用权
  - 用户态切换为内核态：由中断引发，硬件自动完成变态过程，触发中断信号意味着操作系统将强行夺回CPU的使用权
    - 除了非法使用特权指令之外，还有很多事件会触发中断信号。一个共性是，但凡需要操作系统介入的地方，都会触发中断信号


## （五）中断和异常

- 总览：
  - 中断的作用
  - 中断的类型
    - 内中断（异常）
    - 外中断
  - 中断机制的基本原理
- 中断的作用：
  - 中断，会使CPU由用户态变为内核态，使操作系统重新夺回对CPU的控制权
  - 中断，是让操作系统内核夺回CPU使用权的唯一途径
- 中断的类型：
  - 内中断（异常）：与当前执行的指令有关，中断信号来源于CPU内部
    - 内中断的分类：
      - 陷阱、陷入（trap）：有意而为之的异常，如：系统调用
      - 故障（fault）：由错误条件引起的，可能被故障处理程序修复，如：缺页中断
      - 终止（abort）：不可恢复的致命错误造成的结果，终止处理程序不再将控制返回给引发终止的应用程序，如：整数除0
    - 内中断的例子：
      1. 试图在用户态下执行特权指令（终止）
      2. 当前执行的指令是非法的（如：执行除法指令时发现除数为零）（终止）
      3. 应用程序想请求操作系统内核服务，此时会执行一条特殊的指令，陷入指令，该指令会引发一个内部中断信号
         - 注意：执行陷入指令，意味着应用程序主动地将CPU控制权还给操作系统内核。系统调用就是通过陷入指令完成的
  - 外中断：与当前执行的指令无关，中断信号来源于CPU外部
    - 外中断的例子：
      1. 时钟中断：由时钟部件发来的中断信号
      2. IO中断：由输入输出设备发来的中断信号
- 中断机制的基本原理：
  - 不同的中断信号，需要用不同的中断处理程序来处理。当CPU检测到中断信号后，会根据中断信号的类型去查询中断向量表，以此来找到相应的中断处理程序在内存中的存放位置

## （六）系统调用

- 总览：
  - 什么是系统调用？
  - 系统调用和库函数的区别？
  - 为什么系统调用是必须的
  - 什么功能要用系统调用实现
  - 系统调用的过程
- 什么是系统调用，有何作用：
  - 系统调用是操作系统提供给应用程序使用的接口，可以理解为一种可供应用程序调用的特殊函数，应用程序可以通过系统调用来请求获得操作系统内核的服务
- 系统调用和库函数的区别：
  - 普通应用程序，可之间进行系统调用，也可使用库函数，有的库函数设计系统调用，有的不涉及
  - 编程语言，向上提供库函数。有时会将系统调用封装成库函数，以隐藏库函数调用的一些细节
  - 操作系统，向上提供系统调用，使得上层程序能请求内核的服务
- 为什么系统调用是必须的
  - 由操作系统内核对共享资源进行统一的管理，并向上提供系统调用，用户进程想要使用打印机这种共享资源只能通过系统调用向操作系统向操作系统内核发出请求，内核会对各个请求进行协调管理
- 什么功能要用系统调用实现：
  - 应用程序通过系统调用请求操作系统的服务。而系统中的各种共享资源都由操作系统内核统一掌管，因此凡是与共享资源有关的操作（如存储分配，IO操作，文件管理），都必须通过系统调用的方式向操作系统内核提出服务请求，由操作系统内核代为完成。这样可以保证系统的稳定性和安全性，防止用户进行非法操作
  - 按功能分类：
    - 设备管理：完成设备的请求/释放/启动等功能
    - 文件管理：完成文件的读/写/创建/删除等功能
    - 进程控制：完成进程的创建/撤销/阻塞/唤醒等功能
    - 进程通信：完成进程之间的消息传递/信号传递等功能
    - 内存管理：完成内存的分配/回收等功能
- “Linux操作系统提供了哪些系统调用”
- 系统调用的过程：
  - 传递系统调用参数
  - 执行陷入指令（用户态下）
  - 执行相应的内核请求程序处理系统调用（核心态下）
  - 返回应用程序
- 注意别名：陷入指令=trap指令=访管指令

## （七）操作系统体系结构

- 总览：
  - 大内核（又名：宏内核/单内核）
  - 微内核
  - 分层结构
  - 模块化
  - 外核
- 原语：是一种特殊的程序。具有原子性，也就是说，这段程序必须一气呵成，不可被中断
- Ubuntu、CentOS的开发团队，其主要工作是实现非内核功能，而内核都是用Linux内核
- 内核时操作系统最基本、最核心的部分。实现操作系统内核功能的程序就是内核程序
- 操纵系统内核：
  - 时钟管理：实现计时功能
  - 中断处理：负责实现中断机制
  - 原语：
    - 是一种特殊的程序
    - 处于操作系统最底层，是最接近硬件的部分
    - 具有原子性，这段程序必须一气呵成，不可被中断
    - 运行时间较短，调用频繁
  - 对系统资源进行管理的功能：
    - 进程管理
    - 存储器管理
    - 设备管理
- 保留资源管理功能的内核叫大内核；不保留的叫微内核
- 注意：
  - 操作系统内核需要运行在内核态
  - 操作系统的非内核功能运行在用户态
- 大内核和微内核对比：
  - 大内核：
    - 将操作系统的主要功能模块都作为系统内核，运行在核心态
    - 优点：高性能
    - 缺点：内核代码庞大，结构混乱，难以维护
  - 微内核：
    - 只把最基本的的功能保留在内核
    - 优点：内核功能少，结构清晰，方便维护
    - 缺点：需要频繁地在核心态和用户态之间切换，性能低
- 典型的大内核/宏内核/单内核操作系统：Linux、Unix
- 典型的微内核操作系统：Windows NT
- 分层结构：
  - 特性、思想：内核分多层，每层可单向调用更低一层提供的接口
  - 优点：
    1. 便于调试和验证，自底向上逐层调试验证
    2. 易扩充和易维护，各层之间调用接口清晰固定
  - 缺点：
    1. 仅可调用相邻低层，难以合理各层的边界
    2. 效率低，不可跨层调用，系统调用执行时间长
- 模块化：
- 大内核：
- 微内核
- 外核：

## （八）操作系统引导

- 总览：
  - 什么是操作系统引导
  - 磁盘里有哪些相关数据
  - 操作系统引导的过程
- 操作系统引导：
  1. CPU从一个特定主存地址开始，取指令，执行ROM中的引导程序（先进行硬件自检，再开机）
  2. 将磁盘的第一块，主引导记录读入内存，执行磁盘引导程序，扫描分区表
  3. 从活动分区（又称主分区，即安装了操作系统的分区）读入分区引导记录，执行其中的程序
  4. 从根目录下找到完整的操作系统初始化程序（即启动管理器）并执行，完成开机的一系列动作
- windows操作系统的完整开机初始化程序在根目录/Windows/Boot下

## （九）虚拟机

- 虚拟机：使用虚拟化技术，将一台物理机器虚拟化为多台虚拟机器（Virtual Machine，VM），每个虚拟机可以独立运行一个操作系统

- 同义术语：虚拟机管理程序，虚拟机监控程序（Virtual Machine Monitor/Hypervisor）

  - 第一类VMM：直接运行在硬件上
  - 第二类VMM：运行在宿主操作系统上

- 两类虚拟机管理程序VMM的对比：

  - 对物理资源的对比：
    - 第一类：直接运行在硬件之上，能直接控制和分配物理资源
    - 第二类：运行在Host OS之上，依赖于Host OS为其分配物理资源

  - 资源分配方式：
    - 第一类：在安装Guest OS的时候，VMM要在原本的硬盘上自行分配空间，类似于外核的分配方式，分配未经抽象的物理硬件
    - 第二类：Guest OS拥有自己的虚拟硬盘，该盘事件上是Host OS文件系统中的一个大文件。Guest OS分配到的内存是虚拟内存
  - 性能：
    - 第一类：性能更好
    - 第二类：性能更差，需要HostOS作为中介
  - 可支持的虚拟机数量：
    - 第一类：更多，不需要和Host OS竞争资源，相同的硬件资源可以支持更多虚拟机
    - 第二类：更少，Host OS本身需要使用物理资源，Host OS上运行的其他进程也需要物理资源
  - 虚拟机的可迁移性：
    - 第一类：更差
    - 第二类：更好，只需导出虚拟机镜像文件即可迁移到另一台Host OS上，商业化应用更广泛
  - 运行模式：
    - 第一类：运行在最高特权级，可以执行最高特权的指令
    - 第二类：部分运行在用户态、部分运行在核心态。Guest OS发出的系统调用会被VMM截获，并转化为VMM对Host OS的系统调用

# 二.进程管理

## （一）进程的概念、组成、特征

- 总览：
  - 概念，理解进程和程序的概念
  - 组成，一个进程有哪些部分组成
  - 特征，进程有哪些重要的特征
- 进程和程序的概念：
  - 程序：是静态的，就是个存放在磁盘内的可执行文件，就是一系列的指令集合
  - 进程（Process）：是动态的，是程序的一次执行过程
    - 同一个程序多次执行会对应多个进程
- 进程的组成：
  - PCB（Process Control Block），进程控制块，操作系统需要对各个并发运行的进程进行管理，但凡管理时所需要的信息，都会存放在PCB中
    - PCB是进程存在的唯一标志，当进程被创建时，操作系统为其创建PCB，当进程结束时，会回收PCB
  - 程序段：程序的代码（指令序列）
  - 数据段：运行过程中产生的各种数据（如：程序中定义的变量）
    - **注意**：PCB是给操作系统用的，程序 段、数据段是给进程自己用的
- PCB包含的信息：
  - 进程描述信息：
    - 进程表示符PID
    - 用户标识符UID
  - 进程控制和管理信息：
    - CPU、磁盘、网络流量使用情况统计......
    - 进程当前状态(process state)：就绪态/阻塞态/运行态...
  - 资源分配清单：
    - 正在使用哪些文件
    - 正在使用哪些内存区域
    - 正在使用哪些IO设备
  - 处理机相关信息：
    - PSW、PC等等各种寄存器(register)的值（用于实现进程切换）
- 一个进程实体（进程映像）是由PCB、程序段、数据段组成。进程是动态的，进程实体是静态的。进程实体反应了进程在某一时刻的状态。
- 进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位
  - 一个进程被调度，就是指操作系统决定让这个进程在CPU上运行
  - ***注意**：PCB是进程存在的唯一标志
- 进程的特征：
  - 动态性：进程是程序的一次执行过程，是动态地产生、变化和消亡的
    - 动态性是进程最基本的特征
  - 并发性：内存中有多个进程实体，各进程可并发执行
  - 独立性：进程是独立运行、独立获得资源、独立接受调度的基本单位
  - 异步性：各进程按各自独立的、不可预知的速度向前推进，操作系统要提供进程同步机制来解决异步问题
    - 异步性会导致并发执行结果的不确定性
  - 结构性：每一个进程都会配置一个PCB，结构上看，进程由PCB、程序段、数据段组成

## （二）进程的状态和转换

- 总览：
  - 状态：
    - 运行状态（Running）：占有CPU，并在CPU上运行
    - 就绪状态（Ready）：已经具备运行条件，但由于没有空闲CPU，而暂时无法运行
    - 阻塞状态（Waiting/Blocked，又称：等待态）：因等待某一事件而暂时不能运行
      - 以上三个为基本状态
    - 创建状态（New，又称：新建态）：进程正在被创建，操作系统会为进程分配资源、初始化PCB
    - 终止状态（Terminated，又称：结束态）：进程正在从系统中撤销，操作系统会收内存空间等资源、撤销PCB
  - 状态间的转换
    - 就绪态->运行态
    - 运行态->就绪态
    - 运行态->阻塞态
    - 阻塞态->就绪态
  - 进程的组织方式
- 进程状态：
  - 进程正在被创建时，它的状态是创建态，在这个阶段操作系统会为进程分配资源、初始化PCB
  - 当进程创建完毕后，便进入就绪态，处于就绪态的进程以及具备运行条件，但由于没有空闲CPU，就暂时不能运行
  - 如果一个进程此时在CPU上运行，那么这个进程处于运行态。CPU会执行该进程对应的程序
  - 在进程运行的过程中，可能会请求等待某个事件的发生（如等待某种系统资源的分配，或者等待其他进程的响应）。在这个事件发生之前，进程无法继续往下执行，此时操作系统会让这个进程下CPU，并让它进入阻塞态。当CPU空闲时，又会选择另一个就绪态进程上CPU执行
  - 一个进程可以执行exit系统调用，请求操作系统终止该进程。此时该进程会进入终止态，操作系统会让该进程下CPU，并回收内存空间等资源，最后还要回收该进程的PCB。当终止进程的工作结束后，这个进程就彻底消失了
- 进程状态的转换：
  - 创建态->就绪态：admitted，系统完成创建进程的一系列工作
    - 就绪态：处理机√。其他×
  - 就绪态->运行态：进程被调度(dispatch)
    - 运行态：处理机√。其他√
  - 运行态->终止态：exit，进程运行结束，或运行过程中遇到不可修复的错误
  - 运行态->阻塞态：进程用系统调用的方式申请某种系统资源，或者请求等待某个事件发生。
    - 是一种进程自身做出的主动行为
    - 阻塞态：处理机×。其他×
  - 阻塞态->就绪态：申请的资源被分配，或等待的事件发生
    - 不是进程自身能控制的，是一种被动行为
  - 运行态->就绪态：（中断，interrupt），时间片到，或处理机被抢占
  - **注意**：不能由阻塞态直接转换为运行态，也不能由就绪态直接转换为阻塞态（因为进入阻塞态是进程主动请求的，必然需要进程在运行时才能发出这种请求
- 进程PCB中，会有一个变量state来表示进程当前的状态。如：1表示创建态、2表示就绪态、3表示运行态...为零对同一个状态下的各个进程进行统一的管理，操作系统会将各个进程的PCB组织起来
- 进程的组织：
  - 链接方式：
    - 执行指针：指向当前处于运行态的进程，单CPU计算机中，同一时刻只会有一个进程处于运行态
    - 就绪队列指针：指向当前处于就绪态的进程，通常会把优先级高的进程放在队头
    - 阻塞队列指针：指向当前处于阻塞态的指针，很多操作系统还会根据阻塞原因的不同，再分为多个阻塞队列
      - 如：等待打印机的阻塞队列、等待磁盘的阻塞队列
  - 索引方式：
    - 指向指针
    - 就绪表指针
    - 阻塞表指针

## （三）进程控制

- 进程控制：进程控制的主要功能是对系统中的所有进程实施有效的管理，它具有创建新进程、撤销已有进程、实现进程状态转换等功能
  - 简化理解：实现进程状态转换
- 如何实现进程控制：用原语实现
- 进程的创建：
  - 创建原语：
    - 申请空白
    - 为新进程分配资源
    - 初始化PCB
    - 将PCB插入就绪队列
  - 引起进程创建的事件：
    - 用户登录：分时系统中，用户登录成功，系统会为其建立一个新的进程
    - 作业调度：多道批处理系统中，有新的作业放入内存时，会为其建立一个新的进程
    - 提供服务：用户向操作系统提出某些请求时，会新建一个进程处理请求
    - 应用请求：由用户进程主动请求创建一个子进程
- 进程的终止(Termination)：
  - 撤销原语：
    - 从PCB集合中找到终止的PCB
    - 若进程正常运行，立即剥夺CPU，将CPU分配给其他进程
    - 终止其所有子进程
      - 进程间的关系是树形结构
    - 将该进程拥有的资源归还给父进程或操作系统
    - 删除PCB
  - 引起进程终止的事件：
    - 正常结束：进程自己请求终止（exit系统调用）
    - 异常结束：整数除以0，非法使用特权指令
    - 外界干预：Ctrl+Alt+delete，用户选择杀死进程
- 进程的阻塞和唤醒：
  - 进程的阻塞：
    - 阻塞原语：
      - 找到要阻塞的进程对应的PCB
      - 保护进程运行现场，将PCB状态信息设置为阻塞态，暂时停止进程运行
      - 将PCB插入相应事件的等待队列
    - 引起进程阻塞的事件：
      - 需要等待系统分配某种资源
      - 需要等待相互合作的其他进程完成工作
  - 进程的唤醒：
    - 唤醒原语：
      - 在事件等待队列中找到PCB
      - 将PCB从等待队列移除，设置进程为就绪态
      - 将PCB插入就绪队列，等待被唤醒
    - 引起进程唤醒的事件：
      - 等待的事件发生（因何事阻塞，就应由何事唤醒）
- 进程的切换：
  - 切换原语：
    - 将运行环境信息存入PCB
      - 进程上下文(context)
    - PCB移入相应队列
    - 选择另一个进程执行，并更新其PCB
    - 根据PCB恢复新进程所需的运行环境
  - 引起进程切换的事件：
    - 当前进程时间片到
    - 有更高优先级的进程到达
    - 当前进程主动阻塞
    - 当前进程终止
- 无论哪个进程控制原语，要做的无非三类事情：
  - 更新PCB中的信息
  - 将PCB插入合适的队列
  - 分配/回收资源

## （四）进程通信

- 总览：
  - 进程通信：	
    - 共享存储：
      - 基于数据结构共享
      - 基于存储区共享
    - 消息传递
      - 直接通信方式
      - 间接通信方式
    - 管道通信
- 进程通信：
  - 进程间通信（Inter-Process Communication，IPC）是指两个进程之间产生数据交互
- 为什么进程通信需要操作系统支持？
  - 进程是分配系统资源的单位（包括内存地址空间），因此各进程拥有的内存地址空间相互独立。为了保证安全，一个进程不能直接访问另一个进程的地址空间
- 进程通信 --- 共享存储
  - 补充：Linux中，如何实现共享内存：
    - `int shm_open(....);	//通过shm_open系统调用，申请一片共享内存空间`
    - `void * mmap(...);     //通过mmap系统调用，将共享内存区映射到进程自己的地址空间`
  - 通过“增加页表项/段表项”即可将同一片共享内存区映射到各个进程的地址空间中
  - 为避免出错，各个进程对共享空间的访问是互斥的
    - 各个进程可使用操作系统内核提供的同步互斥工具（如P、V操作）
  - 共享存储的两种方式：
    - 基于数据结构的共享：比如共享空间里只能放一个长度为10的数组。这种共享方式速度慢、限制多，是一种低级通信方式
    - 基于存储区的共享：操作系统在内存中划出一块共享存储区，数据的形式，存放位置都由通信控制，而不是操作系统。这种共享方式速度很快，是一种高级通信方式
- 进程通信 --- 消息传递
  - 进程间的数据交换以格式化的消息为单位。进程通过操作系统提供的 发送消息和接收消息 两个原语进行数据交换
  - 消息：
    - 消息头
      - 发送进程ID、接收进程ID、消息长度等格式化的信息
    - 消息体
  - 消息传递的两种方式：
    - 直接通信方式：消息发送进程要指明接收进程的ID
      - 进程A：发送原语，send(B,msg)
      - 进程B：接收原语，receive(A,&msg)
    - 间接通信方式：通过 信箱 间接地通信，因此又称 信箱通信方式
      - 进程A：发送原语，send(A,msg)，往信箱A发送信息msg
      - 进程B：接收原语，receive(A,msg),从信箱A接收信箱
      - **注意**：可以从多个进程往同一个信箱send消息，也可以多个进程从同一个信箱receive信息
- 进程通信 --- 管道通信
  - 进程A -> （写数据）-> 管道 -> (读数据) -> 进程B
  - 管道，是一个特殊的共享文件，又名 pipe 文件。其实就是在内存中开辟了一个大小固定的内存缓冲区
    1. 管道只能采用 半双工通信 ，某一时间段内只能实现单向的传输。如果要实现双向同时通信，则需要设置两个管道
    2. 各进程要互斥地访问管道（由操作系统实现）
    3. 当管道写满时，写进程将阻塞，直到读进程管道将管道中的数据读走，即可唤醒写进程
    4. 当管道读空时，读进程将阻塞，直到写进程往管道中写入数据，即可唤醒读进程
    5. 管道中的数据一旦读出，就彻底消失。因此，当多个进程读同一个管道时，可能会错乱。对此，通常有两种解决方案：
       1. 一个管道允许多个写进程，一个读进程
       2. 允许多个写进程，多个读进程，但系统会让各个读进程轮流从管道中读数据


## （五）线程概念、多线程模型

- 总览：	
  - 什么是线程，为什么要引入线程
  - 引入线程机制后，有什么变化
  - 线程有哪些重要的属性
  - 线程的实现方式
    - 用户级线程
    - 内核级线程
  - 多线程模型
    - 多对一模型
    - 一对一模型
    - 多对多模型
- 什么是线程(Threads)，为什么要引入线程：
  - 有的进程可能需要同时做很多事，而传统的进程只能串行执行一系列程序。为此，引入了线程，来增加并发度
  - 传统的进程是程序执行流的最小单位
  - 引入线程后，线程成为了程序执行流的最小单位
    - 可以把线程理解为 轻量级进程(lightweight process)
  - 线程，是一个基本的CPU执行单元，也是程序执行流的最小单位
    - 引入线程后，不仅是进程之间可以并发，进程内的各线程之间也可以并发，进一步提升了系统的并发度
    - 引入线程后，进程只作为除CPU之外的系统资源的分配单位
- 引入线程机制后，有什么变化：
  - 资源分配、调度
    - 传统进程机制中，进程是资源分配、调度的基本单位
    - 引入线程后，进程是资源分配的基本单位，线程是调度的基本单位
  - 并发性
    - 传统进程机制中，只能进程间并发
    - 引入线程后，各线程之间也能并发，提高了并发度
  - 系统开销
    - 传统的进程间并发，需要切换进程的运行环境，系统开销很大
    - 线程间并发，如果是同一进程内的线程切换，则不需要切换进程环境，系统开销很小
    - 引入线程后，并发所带来的系统开销减小
- 线程的属性
  - 线程是处理机调度的单位
  - 多CPU计算机中，各个线程可占用不同的CPU
  - 每个线程都有一个线程ID、线程控制块TCB
  - 线程也有就绪、阻塞、运行三种基本状态
  - 线程几乎不拥有系统资源
  - 同一进程内的不同线程间共享进程的资源
  - 由于共享内存地址空间，同一进程中的线程间通信甚至无需系统干预
  - 同一进程中的线程切换，不会引起进程切换
  - 不同进程中的线程切换，会引起进程切换
  - 切换同进程内的线程，系统开销很小
  - 切换进程，系统开销较大
- 线程的实现方式
  - 用户级线程（User-Level Thread ，ULT）
    - 早期的操作系统（早期Unix），只支持进程，不支持线程。当时的线程由线程库实现
    - 线程的管理工作是由应用程序通过线程库完成的
    - 线程切换不需要CPU变态
    - 操作系统内核意识不到用户级线程的存在
    - 优缺点：
      - 优点：用户级线程的切换在用户空间即可完成，不需要切换到核心态，线程管理的系统开销小，效率高
      - 缺点：当一个用户级线程被阻塞后，整个进程都被阻塞，并发度不高。多个线程不可在多核处理机上并行运行
  - 内核级线程（Kernel-Level Thread ，KLT）
    - 由操作系统支持的线程。大多数操作系统都实现了内核级线程，如：Windows、Linux
    - 内核级线程的管理工作由操作系统内核完成
    - 线程调度、切换等工作都由内核负责，因此内核级线程的切换必然要在核心态下才能完成
    - 操作系统会为每个内核级线程建立相应的TCB，通过TCB对线程进行管理。内核级，就是 从操作系统内核视角能看到的线程
    - 优缺点：
      - 优点：当一个线程被阻塞后，别的线程还可以继续执行，并发能力强。多线程可在多核处理机上并行执行
      - 缺点：一个用户进程会占用多个内核级线程，线程切换由操作系统内核完成，需要切换到核心态，因此线程管理的成本高，开销大
- 多线程(multithreaded)模型：
  - 在支持内核级线程的系统中，根据用户级线程和内核级线程的映射关系，可以划分为几种多线程模型
  - 一对一模型：
    - 一个用户级线程映射到一个内核级线程。每个用户进程有与用户级线程同样数量的内核级线程
    - 优点：当一个线程阻塞后，别的线程还可以继续执行，并发能力强。多线程可以在多核处理机上执行
    - 缺点：一个用户进程会占用多个内核级线程，线程切换由操作系统内核完成，需要切换到核心态，因此线程管理的成本高，开销大
  - 多对一模型：
    - 多个用户级线程映射到一个内核级线程。且一个进程只被分配一个内核级线程
    - 优点：用户级线程的切换在用户空间即可完成，不需要切换到核心态，线程管理的系统开销小，效率高
    - 缺点：当一个用户级线程被阻塞后，整个进程都被阻塞，并发度不高。多个线程不可在多核处理机上并行运行
    - 重点注意：操作系统只看得见内核级线程，因此只有内核级线程才是处理机分配的单位
  - 多对多模型：
    - n用户级线程映射到m个内核级线程（n>=m）。每个用户进程对应m个内核级线程
    - 克服了多对一模型并发度不高的缺点（一个阻塞全体阻塞），又克服了一对一模型中一个用户进程占用太多内核级线程，开销太大的缺点
      - 可以理解为：
        - 用户级线程是 代码逻辑 的载体
        - 内核级线程是 运行机会 的载体
          - 内核级线程才是处理机分配的单位。
          - 内核级线程中可以运行任意一个有映射关系的用户级线程代码，只有所有内核级线程中正在运行的代码逻辑都阻塞时，这个进程才会阻塞

## （六）线程的状态和转换

- 线程的状态和转换：
  - 运行态->阻塞态：等待某事件
  - 运行态->就绪态：时间用完
  - 就绪态->运行态：被调度程序选中
  - 阻塞态->就绪态：等待的事件发生
- 线程的组织与控制：
  - TCB（线程控制块）：
    - 线程标识符：TID，与PID类似
    - 程序计数器：PC，线程目前执行到哪里
    - 其他寄存器：线程运行的中间结果
    - 堆栈指针：栈堆保存函数调用信息、局部函数等
      - 程序计数器、其他寄存器、堆栈指针，是线程切换时要保存/恢复的
    - 线程运行状态：运行/就绪/阻塞
    - 优先级：线程调度、资源分配的参考
  - 线程表：TCB1、TCB2、TCB3
    - 可将多个TCB组织成一张线程表

## （七）调度的概念、层次

- 总览：
  - 处理机调度：
    - 基本概念
    - 三个层次：
      - 高级调度（作业调度）
      - 中级调度（内存调度）
      - 低级调度（进程调度）
    - 三层调度的联系、对比
    - 补充知识
      - 进程的 挂起态
      - 七状态模型
- 调度(scheduling)的基本概念：
  - 当有一堆任务要处理，但由于资源有限，这些事情没法同时处理。这就需要确定某种规则来处理这些任务的顺序，这就是调度研究的问题
- 调度的三个层次：
  - 高级维度（作业调度）：按一定的原则从外存的作业后备队列中挑选一个作业调入内存，并创建进程。每个作业只调入一次，调出一次。作业调入时会建立PCB，调出时才撤销PCB
    - 外存->内存 （面向作业）
  - 中级调度（内存调度）：按照某种策略决定将哪个处于挂起状态的进程重新调入内存
    - 外存->内存 （面向进程）
    - 内存不够时，可将某些进程的数据调出外存。等内存空闲时或者进程需要运行时再重新调入内存
    - 暂时调到外存等待的进程状态为 挂起状态。被挂起的进程PCB会被组织成 挂起队列
    - 一个进程可能会被多次调出、调入内存，因此中级调度发生的频率比高级调度要高
  - 低级调度（进程调度/处理机调度）：按照某种策略从就绪队列中选取一个进程，将处理机分配给他
    - 内存->CPU 
    - 进程调度是操作系统中最基本的一种调度，在一般的操作系统中都必须配置进程调度
    - 进程调度的频率很高
- 补充知识：
  - 暂时调到外存等待的进程状态为 挂起状态
  - 挂起态又可以进一步细分为 就绪挂起、阻塞挂起 两种状态
  - 五状态模型->七状态模型
  - 注意 挂起 和 阻塞 的区别：两种状态都是暂时不能获得CPU的服务，但挂起态是将进程映像调到外存去了，而阻塞态下的进程映像还在内存中 

## （八）进程调度时机、切换与过程、方式

- 总览：
  - 时机：
    - 什么时候需要进程调度
    - 什么时候不能进行进程调度
  - 切换与过程
    - 狭义的调度与切换的区别
    - 进程切换的过程需要做什么
  - 方式
    - 非剥夺调度方式（非抢占式）
    - 剥夺调度方式（抢占式）
- 进程调度的时机
  - 什么时候需要进程调度：
    - 当前运行的进程主动放弃处理机
      - 进程正常终止
      - 运行过程中发生异常而终止
      - 进程主动请求阻塞
    - 当前运行的进程被动放弃处理机
      - 分给进程的时间片用完
      - 有更紧急的事需要处理
      - 有更高优先级的进程进入就绪队列
  - 什么时候不能进行进程调度：
    - 在处理中断的过程中。中断处理过程复杂，与硬件密切相关，很难做到在中断过程中进行进程切换
    - 进程在操作系统内核程序临界区中（！！！）
      - **注意**：进程处于（普通）临界区时可以进行处理机调度
    - 在原子操作过程中（原语）。原子操作不可中断，要一气呵成（如之前讲过的修改PCB中进程状态标志，并把PCB放到相应队列）
- 进程调度的方式
  - 非剥夺调度方式（非抢占式）：只允许进程主动放弃处理机。在运行过程中即使有更紧迫的任务到达，当前进程依然会继续使用处理机，直到该进程终止或主动要求进入阻塞态
    - 实现简单，系统开销小，但是无法及时处理紧急任务，适合于早期批处理系统
  - 剥夺调度方式（抢占式）：当一个进程正在处理机上执行时，如果有一个更重要或更紧迫的进程需要使用处理机，则立即暂停正在执行的进程，将处理机分配给更重要紧迫的那个进程
    - 可以优先处理更紧急的进程，也可以实现让各个进程按时间片轮流执行的功能（通过时钟中断）。适合于分时操作系统、实时操作系统
- 进程的切换与过程
  - 狭义的进程调度与进程切换的区别
    - 狭义的进程调度，指的是从就绪队列中选中一个要运行的进程（这个进程可以是刚刚被暂停执行的进程，也可能是指另一个进程让出处理机，由另一个进程占用处理机的过程
    - 进程切换是指一个进程让出处理机，由另一个进程占用处理机的过程
    - 广义的进程调度包含了选择一个进程和进程切换两个步骤
  - 进程切换的过程需要做什么
    1. 对原来运行进程各种数据的保存
    2. 对新的进程各种数据的恢复（如：程序计数器、程序状态字、各种数据寄存器等处理机现场信息，这些信息一般保存在进程控制块）
       - 注意：进程切换是有代价的，因此如果过于频繁的进行进程调度、切换，必然会使整个系统的效率降低，使系统大部分时间都花在了进程切换上，而真正用于执行进程的时间减少

## （九）调度器/调度程序

- 就绪态和运行态之间的转换由调度程序引起，调度程序决定：
  - 让谁运行（调度算法）
  - 运行多长时间（时间片大小）
- 调度时机（什么时间会触发 调度程序）
  - 创建新进程
  - 进程退出
  - 运行过程阻塞
  - IO中断发生
  - 非抢占式策略，只有运行进程阻塞或退出才触发调度程序工作
  - 抢占式策略，每个时钟中断或k个时钟中断会触发调度程序工作
- 不支持内核级线程的操作系统，调度程序的处理对象是进程
- 支持内核级线程的操作系统，调度程序的处理对象是内核线程
- 闲逛进程：
  - 没有其他就绪进程时，运行闲逛进程
  - 闲逛进程的特性：
    - 优先级最低
    - 可以是0地址指令，占一个完整的指令周期（指令周期末尾例行检查中断）
    - 能耗低

## （十）调度算法

### 调度算法(scheduling algorithm)的评价指标：

- CPU利用率(CPU utilization)：指CPU忙碌的时间占总时间的比例
  - 利用率 = 忙碌时间 / 总时间
- 系统吞吐量(throughput)：单位时间内完成作业的数量
  - 系统吞吐量 = 总共完成了多少道作业 / 总时间
- 周转时间(turnaround time)
  - 周转时间：指从作业被提交给系统开始，到作业完成为止的时间间隔
    - 共包含四个部分：
      - 作业在外存后备队列上等待作业调度（高级调度）的时间
      - 进程在就绪队列上等待进程调度（低级调度）的时间
      - 进程在CPU上执行的时间
      - 进程等待IO操作完成的时间
    - 周转时间 = 作业完成时间 - 作业提交时间
      - 对用户而言，更关心自己的单个作业的周转时间
    - 平均周转时间 = 各作业周转时间之和 / 作业数
      - 对操作系统而言，更关心系统的整体表现，因此更关心所有作业周转时间的平均值
  - 带权周转时间 = 周转时间 / 作业实际运行时间
    - 带权周转时间 >= 1
    - 带权周转时间和周转时间都是越小越好
    - 平均带权周转时间 = 各作业带权周转时间之和 / 作业数
- 等待时间(waiting time)
  - 计算机的用户希望自己的作业尽可能少的等待处理机
  - 等待时间，指进程/作业处于等待处理机状态时间之和，等待时间越长，用户满意度越低
  - 对于进程来说，等待时间就是指进程建立之后等待被服务的时间之和，在等待IO完成的期间其实进程也是在被服务的，所以不计入等待时间
  - 对于用户来说，不仅要考虑建立进程后的等待时间，还要加上作业在外存后备队列中等待的时间
  - 一个作业总共需要被CPU服务多久，被IO设备服务多久一般是确定不变的，因此调度算法其实只会影响作业/进程的等待时间。也有 平均等待时间
- 响应时间(response time)
  - 对于计算机用户来说，会希望自己提交的请求（比如键盘输入一个调试命令）尽早地开始被系统服务、回应
  - 响应时间，指用户从提交请求到首次产生相应所用的时间

### 调度算法（一）

- 各种调度算法的学习思路：

  1. 算法思想
  2. 算法规则
  3. 这种调度算法是用于 作业调度 还是 进程调度
  4. 抢占式还是非抢占式
  5. 优缺点
  6. 是否会导致饥饿（某进程/作业长期得不到服务）

#### 先来先服务（FCFS，First Come First Serve）

  1. 算法思想：主要从 公平 的角度考虑

  2. 算法规则：按照作业/进程到达的先后顺序进行服务

  3. 这种调度算法是用于 作业调度 还是 进程调度：

     - 用于作业调度时，考虑到是哪个作业先到达后备队列
     - 用于进程调度时，考虑的是哪个进程先到达就绪队列

  4. 抢占式(preemptive)还是非抢占式(nonpreemptive)：非抢占式

        5. 优缺点：

     - 优点：公平、算法实现简单；容易理解
     - 缺点：
       - 排在长作业（进程）后面的短作业需要等待很长时间，带权周转时间很大，对短作业来说用户体验不好。即，FCFS算法对长作业有利，对短作业不利
       - CPU利用率差

  6. 是否会导致饥饿（某进程/作业长期得不到服务）：不会

  7. 例题：各进程到达就绪队列的时间、需要的运行时间如下表所示。使用先来先服务调度算法，计算各进程的等待时间、平均等待时间、周转时间、平均周转时间、带权周转时间、平均带权周转时间

  - | 进程 | 到达时间 | 运行时间 |
    | :--: | :------: | :------: |
    |  A   |    0     |    7     |
    |  B   |    2     |    4     |
    |  C   |    4     |    1     |
    |  D   |    5     |    4     |

  - 调度顺序为 A、B、C、D

  - 甘特图(Gantt Chart)：0、A、7、B、11、C、12、D、16

  - 等待时间 = 周转时间 - 运行时间 = 完成时间 - 运行时间 - 提交时间

    - A = 7 - 7 - 0 = 0、B = 11 - 4 - 2 = 5、C = 12 - 1 - 4 = 7、D = 16 - 4 - 5 = 7

  - 平均等待时间 = 各作业等待时间之和 / 作业数

    - （0 + 5 + 7 + 7） / 4 = 4.75

  - 周转时间 = 作业完成时间 - 作业提交时间

    - A = 7 - 0 = 7、B = 11 - 2 = 9、C = 12 - 4 = 8、D = 16 - 5 =11

  - 平均周转时间 = 周转时间之和 / 作业数

    - （7 + 9 + 8 + 11） / 4 = 8.75

  - 带权周转时间 = 周转时间 / 作业实际运行时间

    - A = 7 / 7 = 1、B = 9 / 4 = 2.25、C = 8 / 1 = 8、D = 11 / 4 = 2.75

  - 平均带权周转时间 = 带权周转时间之和 / 作业数

    - （1 + 2.25 + 8 + 2.75） / 4 = 3.5

  - **注意**：本例中的进程都是纯计算型的进程，一个进程到达后要么在等待，要么在运行。如果是又有计算、又有IO操作的进程，其等待时间 = 周转时间 - 运行时间 - IO操作时间 = 完成时间 - 运行时间 - IO操作时间 - 提交时间

#### 短作业优先（SJF，Shortest Job First）

  1. 算法思想：追求最少的平均等待时间，最少的平均周转时间、最少的平均带权周转时间

  2. 算法规则：

     - 最短的作业/进程优先得到服务（最短，指要求服务时间最短）
     - 具体描述：每次调度时选择当前已到达且运行时间最短的作业/进程

  3. 这种调度算法是用于 作业调度 还是 进程调度：

     - 既可用于作业调度，也可用于进程调度。用于进程调度时称为“短进程优先（SPF，Shortest Process First）算法”

  4. 抢占式还是非抢占式：

     - SJF和SPF是非抢占式算法
     - 但也有抢占式的版本（最短剩余时间优先算法，SRTN，SHortest Remaining Time Next）
       - 最短剩余时间优先算法具体描述：每当有进程加入，就绪队列改变时，就需要调度，如果新到达的进程剩余时间(remaining time)比当前运行的进程剩余时间更短，则由新进程抢占处理机，当前运行进程重新回到就绪队列。另外，当一个进程完成时也需要调度

  5. 优缺点：

     - 优点：可以得到“最短的”平均等待时间、平均周转时间
     - 缺点：不公平。对短作业有利，对长作业不利。可能产生饥饿现象。另外，作业/进程的运行时间由用户提供，并不一定真实，因此不一定能做到真正的短作业优先（？？？）

  6. 是否会导致饥饿（某进程/作业长期得不到服务）：会。如果源源不断有短作业到达，可能使长作业长时间得不到服务。如果一直得不到服务，则称为“饿死”

  7. 注意事项：

       1. 如果题目中未特别说明，所提到的 短作业/进程优先算法 默认是非抢占式的
       2. 很多书上都会说“SJF调度算法的平均等待时间、平均周转时间最少”。严格来说，这个表述是错误的，不严谨的。因为最短剩余时间优先算法得到的平均等待时间、平均周转时间更少。应该加上一个条件“在所有进程（几乎）同时可运行时，采用SJF调度算法的平均等待时间、平均周转时间更少（因为这样就最短剩余时间优先算法的调度顺序基本保持了一致）。如果不加上述条件，则最短剩余时间优先算法的平均等待时间、平均周转时间最少。
       3. 虽然严格来说，SJF的平均等待时间、平均周转时间不一定最少，但相比于FCFS和高响应比算法来说，SJF依然可以获得更少的平均等待时间、平均周转时间

  8. 非抢占式的短作业优先算法例题：各进程到达就绪队列的时间、需要的运行时间如下表所示。使用**非抢占式的短作业优先算法**，计算各进程的等待时间、平均等待时间、周转时间、平均周转时间、带权周转时间、平均带权周转时间

  - | 进程 | 到达时间 | 运行时间 |
    | :--: | :------: | :------: |
    |  A   |    0     |    7     |
    |  B   |    2     |    4     |
    |  C   |    4     |    1     |
    |  D   |    5     |    4     |

  - 短作业优先算法：每次调度时选择当前已到达且运行时间最短的作业/进程

    - 调度顺序：A、C、B、D

    - 0、A、7、C、8、B、12、C、16

  - 等待时间 = 周转时间 - 运行时间 = 完成时间 - 运行时间 - 提交时间

    - A = 7 - 7 - 0 = 0、B = 12 - 4 - 2 = 6、C = 8 - 1 - 4 = 3、D = 16 - 4 - 5 = 7

  - 平均等待时间 = 各作业等待时间之和 / 作业数

    - （0 + 6 + 3+ 7） / 4 = 4

  - 周转时间 = 作业完成时间 - 作业提交时间

    - A = 7 - 0 = 7、B = 12 - 2 = 10、C = 8 - 4 = 4、D = 16 - 5 = 11

  - 平均周转时间 = 周转时间之和 / 作业数

    - （7 + 10 + 4 + 11） / 4 = 8

  - 带权周转时间 = 周转时间 / 作业实际运行时间

    - A = 7 / 7 = 1、B = 10 / 4 = 2.5、C = 4 / 1 = 4、D = 11 / 4 = 2.75

  - 平均带权周转时间 = 带权周转时间之和 / 作业数

    - （1 + 2.5 + 4 + 2.75） / 4 = 2.56

  - 对比FCFS算法，SPF算法的 平均等待、平均周转、平均带权周转时间都要更低

  9. 抢占式的短作业优先算法例题：各进程到达就绪队列的时间、需要的运行时间如下表所示。使用**抢占式的短作业优先算法（又称，最短剩余时间优先算法）**，计算各进程的等待时间、平均等待时间、周转时间、平均周转时间、带权周转时间、平均带权周转时间

  - | 进程 | 到达时间 | 运行时间 |
    | :--: | :------: | :------: |
    |  A   |    0     |    7     |
    |  B   |    2     |    4     |
    |  C   |    4     |    1     |
    |  D   |    5     |    4     |

  - 最短剩余时间优先算法：每当有进程加入，就绪队列改变时，就需要调度，如果新到达的进程剩余时间比当前运行的进程剩余时间更短，则由新进程抢占处理机，当前运行进程重新回到就绪队列。另外，当一个进程完成时也需要调度。重新分析调度顺序：

    - 0时刻，只有A到达，剩余时间7，记为A（7）；选择A运行
    - 2时刻，B到达；A（5）、B（4）；B抢占处理机，A重新回到就绪队列
    - 4时刻，C到达；A（5），B（2），C（1）；C抢占处理机，B下机
    - 5时刻，C完成，D到达；A（5），B（2），D（4）；B抢占处理机
    - 7时刻，B完成；A（5），D（4）；D抢占处理机
    - 11时刻，D完成；A（5）；A抢占处理机
    - 16时刻，A完成

  - 0、A、2、B、4、C、5、B、7、D、11、A、16

  - 等待时间 = 周转时间 - 运行时间 = 完成时间 - 运行时间 - 提交时间

    - A = 16 - 7 - 0 = 9、B = 7 - 4 - 2 = 1、C = 5 - 1 - 4 = 0、D = 11 - 4 - 5 = 2

  - 平均等待时间 = 各作业等待时间之和 / 作业数

    - （9 + 1 + 0+ 2） / 4 = 3

  - 周转时间 = 作业完成时间 - 作业提交时间

    - A = 16 - 0 = 16、B = 7 - 2 = 5、C = 5 - 4 = 1、D = 11 - 5 = 6

  - 平均周转时间 = 周转时间之和 / 作业数

    - （16 + 5 + 1 + 6） / 4 = 7

  - 带权周转时间 = 周转时间 / 作业实际运行时间

    - A = 16 / 7 = 2.28、B = 5 / 4 = 1.25、C = 1 / 1 = 1、D = 6 / 4 = 1.5

  - 平均带权周转时间 = 带权周转时间之和 / 作业数

    - （2.28 + 1.25 + 1 + 1.5） / 4 = 1.5

  - 对比非抢占式算法，抢占式算法的 平均等待、平均周转、平均带权周转时间还要更低

#### 高响应比优先（HRRN）

1. 算法思想：综合考虑作业/进程的等待时间和要求服务时间

2. 算法规则：在每次调度时先计算各个作业/进程的响应比，选择响应比最高的作业/进程为其服务

   - 响应比 = （等待时间 + 要求服务时间）/ 要求服务时间

3. 这种调度算法是用于 作业调度 还是 进程调度：既可用于作业调度，也可用于进程调度

4. 抢占式还是非抢占式：非抢占式。因此只有当前运行的作业/进程主动放弃处理机时，才需要调度，计算响应比

5. 优缺点：

   - 综合考虑了等待时间和运行时间
   - 等待时间相同时，要求服务时间短的优先（SJF的优先）
   - 要求服务时间相同时，等待时间长的优先（FCFS优先）
   - 对于长作业来说，随着等待时间越来越久，其响应比也会越来越大，从而避免了长作业饥饿的问题

6. 是否会导致饥饿（某进程/作业长期得不到服务）：不会

7. 高响应比优先例题：各进程到达就绪队列的时间、需要的运行时间如下表所示。使用**高响应比优先算法**，计算各进程的等待时间、平均等待时间、周转时间、平均周转时间、带权周转时间、平均带权周转时间

   - | 进程 | 到达时间 | 运行时间 |
     | :--: | :------: | :------: |
     |  A   |    0     |    7     |
     |  B   |    2     |    4     |
     |  C   |    4     |    1     |
     |  D   |    5     |    4     |

   - 高响应比优先算法：非抢占式调度算法，只有当前运行的作业/进程主动放弃处理机（正常/异常完成，或主动阻塞）时，才需要调度，计算响应比，调度时计算所有就绪进程的响应比，选响应比最高的进程上处理机

     - 0时刻，只有A到达；A上处理机

     - 7时刻，A完成，B、C、D到达；B的响应比：（7 - 2 + 4）/ 4 = 2.25，C：（7 - 4 + 1）/ 1 = 4，D：（7 - 5 + 4）/ 4 =1.5；C上处理机

     - 8时刻，C完成；B：（8 - 2 + 4）/ 4 = 2.5，D：（8 - 5 + 4）/ 4 = 1.75；B上处理机

     - 12时刻，B完成；D上处理机

     - 16时刻，D完成

   - 0、A、7、C、8、B、12、C、16

   - 等待时间 = 周转时间 - 运行时间 = 完成时间 - 运行时间 - 提交时间

     - A = 7 - 7 - 0 = 0、B = 12 - 4 - 2 = 6、C = 8 - 1 - 4 = 3、D = 16 - 4 - 5 = 7

   - 平均等待时间 = 各作业等待时间之和 / 作业数

     - （0 + 6 + 3+ 7） / 4 = 4

   - 周转时间 = 作业完成时间 - 作业提交时间

     - A = 7 - 0 = 7、B = 12 - 2 = 10、C = 8 - 4 = 4、D = 16 - 5 = 11

   - 平均周转时间 = 周转时间之和 / 作业数

     - （7 + 10 + 4 + 11） / 4 = 8

   - 带权周转时间 = 周转时间 / 作业实际运行时间

     - A = 7 / 7 = 1、B = 10 / 4 = 2.5、C = 4 / 1 = 4、D = 11 / 4 = 2.75

   - 平均带权周转时间 = 带权周转时间之和 / 作业数

     - （1 + 2.5 + 4 + 2.75） / 4 = 2.56

8. 对比FCFS、SJF、HRRN三种算法，这三种算法主要关心用户的公平性、平均周转时间。平均等待时间等评价系统整体性能的指标，但是不关心 响应时间 ，也不区分任务的紧急程度，因此对其他用户来说，交互性很糟糕。因此这三种算法一般适合用于早期的批处理系统，FCFS算法也常结合其他算法使用，在现在也扮演者很重要的角色。

### 调度算法（二）

#### 时间片轮转调度算法（RR，Round-Robin），轮循算法

1. 算法思想：公平地、轮流地为各个进程服务，让每个进程在一定时间间隔内都可以得到响应

2. 算法规则：按照各进程到达就绪队列的顺序，轮流让各个进程执行一个时间片(time interval)（如100ms）。若进程未在一个时间片内执行完，则剥夺处理机，将进程重新放到就绪队列队尾重新排队

3. 这种调度算法是用于 作业调度 还是 进程调度：用于进程调度（只有作业放入内存建立了相应的进程后，才能被分配处理机的时间片）

4. 抢占式还是非抢占式：若进程未能在时间片内运行完，将被强行剥夺处理机使用权，因此时间片轮转算法属于抢占式算法。由时钟装置发出时钟中断来通知CPU时间片已到

5. 优缺点：

   - 优点：公平；响应快，适用于分时操作系统
   - 缺点：由于高频率的进程切换，因此有一定开销；不区分人物的紧急程度

6. 是否会导致饥饿（某进程/作业长期得不到服务）：不会

7. 时间片轮转例题：各进程到达就绪队列的时间、需要的运行时间如下表所示。使用时间片轮转算法（常用于分时操作系统，更注重 像响应时间，因此不计算周转时间），分析时间片大小分别是2、5时的进程运行情况

   - | 进程 | 到达时间 | 运行时间 |
     | :--: | :------: | :------: |
     |  A   |    0     |    5     |
     |  B   |    2     |    4     |
     |  C   |    4     |    1     |
     |  D   |    5     |    6     |

   - 时间片轮转调度算法：轮流让就绪队列中的进程依次执行一个时间片（每次选择的都是就绪队列队头的进程）

   - 时间片大小为2时：

     - 0时刻，只有A到达；A（5）；A上处理机
     - 2时刻，B到达；B（4）->A（3） ；A运行完一个时间片，下处理机，放到队尾；B上处理机
       - 默认新到达的进程先进入就绪队列，也可根据题目的特殊规定而改变
     - 4时刻，C到达，A没有离开过就绪队列，C先进入就绪队列是相对刚下处理机的B而言，所以C排在A后面，B去最后面；A（3）->C（1）->B（2）；B下，A上
     - 5时刻，D到达，D进入就绪队列队尾，而A的时间片还未用完，不发生调度；C（1）->B（2）->D（6）
       - 此时A不在就绪队列，因为A处于运行态
     - 6时刻，A时间片结束；C（1）->B（2）->D（6）->A（1）；A下、C上
     - 7时刻，C结束，发生调度；B（2）->D（6）->A（1）；C下、B上
     - 9时刻，B结束；D（6）->A（1）；B下、D上
     - 11时刻，D时间片结束；A（1）->D（4）；D下、A上
     - 12时刻，A结束；D（4）；A下、D上
     - 14时刻，D时间片结束；D（2）
     - 16时刻，D结束；所有进程结束

   - 时间片大小为5时：

     - 0时刻，只有A到达；A（5）；A上处理机
     - 2时刻，B到达，而A的时间片还未结束；B（4）
     - 4时刻，C到达，A的时间片还未结束；B（4）->C（1）
     - 5时刻，D到达，A结束，发生调度；B（4）->C（1）->D（6）；A下，B上
     - 9时刻，B结束，发生调度；C（1）->D（6）；B下，C上
     - 10时刻，C结束，发生调度；D（6）
     - 15时刻，D时间片结束，但就绪队列为空，D继续执行；
     - 16时刻，D结束；所有进程结束

   - 因此，如果时间片太大，使得每一个进程都可以在一个时间片内完成，则时间片轮转算法退化为先来先服务调度算法，并且会增大进程响应时间。因此时间片不能太大

   - 另一方面，进程调度、切换是有时间代价的，因此如果时间片太小，会导致进程切换过于频繁，系统会花大量时间来处理进程切换，从而导致实际用于进程时间的比例减小。因此时间片不能太小

     - 一般来说，设计时间片时要让切换进程的开销占比不超过百分之1

#### 优先级调度(Priority scheduling)算法

1. 算法思想：随着计算机的发展，特别是实时操作系统的出现，越来越多的应用场景需要根据任务的紧急程度来决定处理顺序

2. 算法规则：每个作业/进程有各自的优先级，调度时选择优先级最高的作业/进程

3. 这种调度算法是用于 作业调度 还是 进程调度：既可用于作业调度，也可用于进程调度。甚至可以用于IO调度

4. 抢占式还是非抢占式：抢占式和非抢占式都有。区别在于：非抢占式只需要在进程主动放弃处理机时进行调度即可，而抢占式还需在就绪队列变化时，检查是否会发生抢占

5. 优缺点：

   - 优点：用优先级区分紧急任务、重要程度，适用于实时操作系统。可灵活地调整对各种作业/进程的偏好程度
   - 缺点：若源源不断有高优先级进程到来，则可能导致饥饿

6. 是否会导致饥饿（某进程/作业长期得不到服务）：会

7. 优先级调度算法例题：各进程到达就绪队列的时间、需要的运行时间、进程优先数如下表所示。使用**非抢占式的优先级调度算法**，分析进程运行情况（注：优先数越大，优先级越高）

   - | 进程 | 到达时间 | 运行时间 | 优先数 |
     | :--: | :------: | :------: | :----: |
     |  A   |    0     |    7     |   1    |
     |  B   |    2     |    4     |   2    |
     |  C   |    4     |    1     |   3    |
     |  D   |    5     |    4     |   2    |

   - 非抢占式的优先级调度算法：每次调度时选择当前已到达且优先级最高的进程。当前进程主动放弃处理机时发生调度

     - 0时刻，只有A到达；A上
     - 7时刻，A完成，B、 C、D都到达；C优先级最高；C上
     - 8时刻，C完成；B、D优先级相同，而B先到达；B上
     - 12时刻，B完成；D上
     - 16时刻，D完成；所有进程结束

   - 抢占式的优先级调度算法：每次调度时选择当前已到达且优先级最高的进程。当前进程主动放弃处理机时发生调度。另外，当就绪队列发生改变时要检查一次是否发生抢占

     - 0时刻，只有A到达；A（7）；A上
     - 2时刻，B到达；B的优先级更高，B（4）、A（5）；A下，B上
     - 4时刻，C到达；C的优先级最高，C（1）、B（2）、A（5）；B下，C上
     - 5时刻，C完成，D到达；B、D优先级相同，而B先到达，B（2）、A（5）、D（4）；C下、B上
     - 7时刻，B完成；D高，A（5）、D（4）；B下、D上
     - 11时刻，D完成；A（5）；D下、A上
     - 16时刻，A完成；所有进程结束

8. 补充：

   - 如何合理地设置各类进程的优先级：
     - 系统进程优先级高于用户进程
     - 前台进程高于后台进程
     - 操作系统更偏好IO型进程（又称，IO繁忙型进程）
       - 相对，计算型进程（又称，CPU繁忙型进程）
       - IO设备和CPU可以并行工作。如果优先让IO繁忙型进程优先运行的话，则越有可能让设备尽早地投入工作，则资源利用率、系统吞吐量都会得到提升
   - 如果采用的是动态优先级，什么时候应该调整
     - 可以从追求公平、提升资源利用率等角度考虑：
       - 如果某进程在就绪队列中等待了很长时间，则可以适当提高优先级
       - 如果某进程占用处理机运行了很长时间，则可以适当降低优先级
       - 如果发现一个进程频繁地运行IO操作，则可以适当提高优先级

9. 对以上多种调度算法的思考：

   - FCFS算法的优点是 公平
   - SJF算法的优点是能尽可能处理完短作业，平均等待/周转时间等参数优秀
   - 时间片轮转调度算法可以让各个进程得到及时的响应
   - 优先级调度算法可以灵活地调整各种进程被服务的机会

#### 多级反馈队列(multilevel feedback queue)算法

1. 算法思想：对其他调度算法的折中权衡

2. 算法规则：

   1. 设置多级就绪队列，各级队列优先级从高到低，时间片从小到大
   2. 新进程到达时先进入第一级队列，按FCFS原则排队等待被分配时间片，若用完时间片进程还未结束，则进程进入下一级队列队尾。若此时已经是最下级的队列，则重新回到该队列队尾
   3. 只有第k级队列为空时，才会为k+1级队头的进程分配时间片

3. 这种调度算法是用于 作业调度 还是 进程调度：用于进程调度

4. 抢占式还是非抢占式：抢占式算法，在k级队列的进程运行过程中，若更上级的队列（1~k-1级）中进入了一个新的进程，则由于新进程处于优先级更高的队列中，因此新进程会抢占处理机，原来运行的进程放回k级队列队尾

5. 优缺点：

   - 对各类进程相对公平（FCFS的优点）
   - 每个新到达的进程都可以很快就得到响应（RR的优点）
   - 短进程只用很少的时间就可以完成（SPF）的优点
   - 不必实现估计进程的运行时间（避免用户作假）
   - 可灵活地调整对各类进程的偏好程度，比如CPU密集型进程、IO密集型进程
     - 可以将因IO阻塞的进程重新放回原队列，这样IO型进程就可以保持较高优先级

6. 是否会导致饥饿（某进程/作业长期得不到服务）：会

7. 多级反馈队列调度算法：各进程到达就绪队列的时间、需要的运行时间如下表所示。使用**多级反馈调度算法**，分析进程运行情况

   - | 进程 | 到达时间 | 运行时间 |
     | :--: | :------: | :------: |
     |  A   |    0     |    8     |
     |  B   |    1     |    4     |
     |  C   |    5     |    1     |

   - 设置多级就绪队列，各级队列优先级从高到低，时间片从小到大（例：第一级1个时间片、第二级2个时间片、第三级3个时间片）

   - 新进程到达时先进入第一级队列，按FCFS原则排队等待被分配时间片。若用完时间片进程还未结束，则进程进入下一级队列队尾。如果此时已经在最下级的队列，则重新放回最下级队列队尾

   - 只有第k级队列为空时，才会为k+1级队头的进程分配时间片

   - 被抢占处理机的进程重新回到原队列队尾

   - 顺序：

     - A（1）
     - B（1）
     - A（2）
     - B（1）
     - C（1）
     - B（2）
     - A（4）
     - A（1）

8. 注：比起早期的批处理操作系统来说，由于计算机造价大幅降低，因此之后出现的交互式操作系统（包括分时操作系统、实施操作系统等）更注重系统的响应时间、公平性、平衡性等指标。而这几种算法恰好也能较好地满足交互式系统的需求。因此这三种算法适合用于交互式系统（比如Unix使用的就是多级反馈调度算法）

#### 多级队列(multilevel queue)调度算法

- 系统中按进程类型设置多个队列，进程创建后插入某个队列
  - 最高优先级到最低优先级依次为：
    - 系统进程（如：内存管理进程）
    - 交互式(interactive)进程（如：游戏、打字软件）
    - 批处理(batch)进程（如：AI模型训练、视频训练渲染）
- 队列之间可采取固定优先级，或时间片划分
  - 固定优先级：高优先级空时低优先级进程才能被调度
  - 时间片划分：如三个队列分配时间50%
- 各队列可采用不同的调度策略：
  - 系统进程队列采用优先级调度
  - 交互式队列采用RR
  - 批处理队列采用FCFS

## （十一）进程同步、进程互斥

- 总览：
  - 同步、互斥问题
    - 什么是进程同步
    - 什么是进程互斥
  
- 进程同步：

  - 同步，亦称直接制约关系，它是指为完成某种任务而建立的两个或多个进程，这些进程因为需要在某些位置上协调它们的工作次序而产生的制约关系。进程间的直接制约关系就是源自它们之间的相互合作

- 进程互斥：

  - 补充：我们把一个时间段内只允许一个进程使用的资源称为临界资源。许多物理设备（如：摄像头，打印机）都属于临界资源。此外，还有许多变量、数据、内存缓冲区等都属于临界资源

  - 对邻接资源的的访问，必须互斥地进行。

  - 互斥，亦称简介制约关系。进程互斥指当一个进程访问某临界资源时，另一个想要访问该临界资源的进程必须等待。当前访问临界资源的进程访问结束，释放该资源之后，另一个进程才能去访问临界资源

  - 对临界资源的互斥访问，可以在逻辑上分为如下四部分：

    - ```
      do{
      	entry section;	//进入区：负责检查是否可以进入临界区，若可进入，则设置“正在访问临界资源的标志（可以理解为上锁）”，以阻止其他进程同时进入临界区
      	cirtical section;	//访问临界资源的那段代码
      	exit section;	//负责解除“正在访问临界资源的标志（可以理解为解锁）”
      	remainder section;	//做其他处理
      }
      ```

    - 注意：

      - 临界区，是进程中访问临界资源的代码段
      - 进入区和退出区，是负责实现互斥的代码段
      - 临界区，也可称临界段

  - 为了实现对临界资源的互斥访问，同时保证系统整体性能，需要遵循以下原则：

    1. 空闲让进。临界区空闲时，可以允许一个请求进入临界区的进程立刻进入临界区
    2. 忙则等待。当已有进程进入临界区时，其他试图进入临界区的进程必须等待
    3. 有限等待。当请求访问的进程，应保证能在有限时间内进入临界区（保证不会饥饿）
    4. 让权等待。当进程不能进入临界区时，应立刻释放处理机，防止进程忙等待

## （十二）进程互斥的软件实现方法

- 总览：

  - 单标志法
  - 双标志先检查
  - 双标志后检查
  - Perterson算法

- 学习提示：

  - 理解各个算法的思想、原理
  - 结合实现互斥的四个逻辑部分，重点理解各算法在进入区、退出区都做了什么
  - 分析各算法存在的缺陷（结合实现进程互斥的四个原则）

### 单标志法：

- 算法思想：

    - 两个进程在访问完临界区后会把使用临界区的权限转交给另一个进程。也就是说每个进程进入临界区的权限只能被另一个进程赋予

- ```
  int turn = 0;	//turn表示当前允许进入临界区的进程号
  P0进程：
  	while(turn != 0);	//1	进入区
  	critical section;	//2	临界区
  	turn = 1;	//3	退出区
  	remainder section;	//4	剩余区
  P1进程：
  	while(turn != 1);	//5
  	critical section;	//6
  	turn = 0;	//7
  	remainder section;	//8
  	
  ```

  - turn的初值为0，即刚开始只允许0号进程进入临界区

  - 若P1先上处理机运行，则会一直卡在5。直到P1的时间片用完，发生调度，切换到P0上运行。代码1不会卡住P0，P0可以正常访问临界区，在P0访问临界区期间即使切换回P1，P1依然会卡在5。只有P0在退出区将turn改为1后，P1才能进入临界区

  - 因此，该算法可以实现 同一时刻最多只允许一个进程访问临界区

- 算法存在的缺陷：这种算法只能轮流访问，带来的问题是：如果此时允许进入临界区的进程是P0，而P0一直不访问临界区，那么此时临界区空闲，但是不允许P1访问。因此，单标志法存在的主要问题是：违背 空闲让进 原则

### 双标志先检查法

- 算法思想：

  - 设置一个布尔型数组 flag[]，数组中各个元素用来标记各进程想要进入临界区的意愿，比如“flag[0] = true”意味着0号进程P0现在想要进入临界区。每个进程在进入临界区之前先检查当前有没有其他进程想进入临界区，如果没有，则把自身对应的标志flag[i]设为true，之后开始访问临界区

- ```
  bool flag[2];	//表示进入临界区意愿的数组
  flag[0] = flase;
  flag[1] = flase;
  P0进程：
  	while(flag[1] != 0);	//1	如果此时P1想进入临界区，则P0就一直循环等待
  	flag[0] = true;	//2	标记为P0进程想要进入临界区
  	critical section;	//3	访问临界区
  	flag[0] = flase;	//4	访问完临界区，修改标记为P0不想使用临界区
  	remainder section;	
  P1进程：
  	while(flag[0] != 0);	//5
  	flag[1] = true;		//6
  	critical section;	//7
  	flag[1] = flase;	//8
  	remainder section;
  ```

- 算法缺陷：

  - 若按照152637...的顺序执行，P0和P1会同时访问临界区
  - 因此，双标志先检查法的主要问题是：违法 忙则等待 原则
    - 原因在于，进入区的检查和上锁两个处理不是一气呵成的，检查后，上锁前可能发生进程切换

### 双标志后检查法

- 算法思想：

  - 双标志先检查法的改版。前一个算法的问题是先检查后上锁，但是这两个操作又无法一气呵成，因此导致两个进程同时进入临界区的问题。因此，人们想到先上锁后检查的方法，来避免上述问题

- ```
  bool flag[2];	//表示进入临界区意愿的数组
  flag[0] = flase;
  flag[1] = flase;	//刚开始设置两个进程都不想进入临界区
  P0进程：
  	flag[0] = true;	//1	标记为P0进程想要进入临界区
  	while(flag[1] != 0);	//2	如果此时P1想进入临界区，则P0就一直循环等待
  	critical section;	//3	访问临界区
  	flag[0] = flase;	//4	访问完临界区，修改标记为P0不想使用临界区
  	remainder section;	
  P1进程：
  	flag[1] = true;		//5
  	while(flag[0] != 0);	//6
  	critical section;	//7
  	flag[1] = flase;	//8
  	remainder section;
  ```

- 算法缺陷：

  - 若按照152637...的顺序执行，P0和P1都无法访问临界区
  - 因此，双标志后检查法虽然解决了 忙则等待 的问题，但是又违背了 空闲让进、有限等待
    - 原因在于，会因各进程都长期无法访问临界资源而产生饥饿现象

### Peterson算法

- 算法思想：

  - 结合双标志法、单标志法的思想。如果双方都争着想进入临界区，那可以让进程尝试谦让，做一个有礼貌的进程

- ```
  bool flag[2];	//表示进入临界区意愿的数组（表达意愿）
  flag[0] = flase;
  flag[1] = flase;	//刚开始设置两个进程都不想进入临界区
  int turn = 0;	//turn表示优先让哪个进程进入临界区（表达谦让）
  P0进程：
  	flag[0] = true;	//1	标记为P0进程想要进入临界区
  	turn = 1	//2	可以优先让对方进入临界区（表达谦让）
  	while(flag[1] && turn == 1);	//3	如果此时对方想进入临界区，且最后一次是自己表达了谦让，则自己一直循环等待
  	critical section;	//4	访问临界区
  	flag[0] = flase;	//5	访问完临界区，修改标记为P0不想使用临界区
  	remainder section;	
  P1进程：
  	flag[1] = true;		//5
  	while(flag[0] != 0);	//6
  	critical section;	//7
  	flag[1] = flase;	//8
  	remainder section;
  ```

  - 进入区（123）：
    - 1.主动谦让
    - 2.主动争取
    - 3.检查对方是否也想使用，且最后一次是不是自己表达谦让

- 算法推导（按不同顺序执行）：

  - 123678...
  - 1623...
  - 13678...
  - 16278...

- 算法分析：

  - Perterson算法用软件方法解决了进程互斥问题，遵循了空闲让进、忙则等待、优先等待三个原则，但是依然未遵循让权等待的原则
  - Perterson相较于前三种软件方法是最好的，但仍不是最好的

## （十三）进程互斥的硬件实现方法

- 总览：
  - 中断屏蔽方法
  - TestAndSet（TS指令/TSL指令）
  - Swap指令（XCHG指令）
- 学习提示：
  - 理解各方法的原理
  - 了解各方法的优缺点

### 中断屏蔽方法

- 利用“开/关中断方法”实现（与原语的实现思想相同，即在某进程开始访问临界区到结束访问为止都不允许被中断，也就不能发生进程切换，因此也不能发生两个同时访问临界区的情况）
  - 关中断后，不允许当前进程被中断，也必然不会发生进程切换
  - 直到当前进程访问完临界区，再执行开中断指令，才有可能有别的进程上处理机并访问临界区
- 优缺点：
  - 优点：简单、高效
  - 缺点：不适合用于多处理机；只适合用于操作系统内核进程，不适合用户进程（因为开/关中断指令只能运行在内核态，这组指令如果能让用户随意使用会很危险）

### TestAndSet（TS指令/TSL指令）

- 简称TS指令，也有称TestAndSetLock（简称TSL指令）

  - TSL指令是用硬件实现的，执行过程不允许中断，只能一气呵成

- C语言描述逻辑：

  - ```c
    //布尔型共享变量lock表示当前临界区是否被加锁
    //true表示已加锁，false表示未加锁
    bool TestAndSet(bool *lock)
    {
        bool old;
        old = *lock;	//old用来存放lock原来的值
        *lock = true;	//无论之前是否已加锁，都将lock设置为true
        return old;	//返回lock原来的值
    }
    //以下是使用TSL指令实现互斥的算法逻辑
    while(TestAndSet(&lock));//上锁并检查
    ...//临界区代码段
    lock = false;	//解锁
    ...//剩余区代码段
    ```

- 若刚开始lock是false，则TSL返回的old值为false，while循环条件不满足，直接进入循环，进入临界区。若刚开始lock是true，则执行TSL后old返回的值为true，while循环条件满足，会一直循环，直到当前访问临界区的进程在退出区进行解锁（？？？）

- 相比软件实现方法，TSL指令把上锁和检查操作用硬件的方式变成了一气呵成的原子操作。

- 优点：实现简单，无需像软件实现方法那样严格检查是否会有逻辑漏洞；适合用于多处理机环境

- 缺点：不满足让权等待原则，暂时无法进入临界区的进程会占用CPU并循环TSL指令，从而造成忙等

### Swap指令

- 有的地方叫Exchange指令，或简称XCHG指令

- Swap指令是硬件实现的，执行过程不允许中断，只能一气呵成。

- C语言描述的逻辑：

  - ```c
    //Swap指令的作用是交换两个变量的值
    Swap(bool *a, bool *b)
    {
        bool temp;
        temp = *a;
        *a = *b;
        *b = temp;
    }
    //以下是用Swap指令实现互斥的算法逻辑
    //lock表示当前临界区是否被加锁
    bool old = true;
    while(old == true)
        Swap(&lock,&old);
    ...//临界区代码段
    lock = false;
    ...//剩余区代码段
    ```

- 逻辑上看Swap和TSL并无太大区别，都是先记录下此时临界区是否已经被上锁（记录在old变量上），再将上锁标记lock设置为true，最后检查old，如果old为false则说明之前没有别的进程对临界区上锁，则可跳出循环，进去临界区

- 优点：实现简单，无需像软件实现方法那样严格检查是否会有逻辑漏洞；适合用于多处理机环境

- 缺点：不满足让权等待原则，暂时无法进入临界区的进程会占用CPU并循环TSL指令，从而造成忙等

## （十四）互斥锁（进程互斥：锁）

- 互斥锁：

  - 解决临界问题最简单的工具就是互斥锁（mutex lock）。一个进程在进入临界区时应获得锁；在退出临界区时释放锁。函数acquire()获得锁，函数release()释放锁

  - 每个互斥锁有一个布尔变量available，表示锁是否可用。如果锁是可用的，调用acquire()会成功，且锁不再可用。当一个进程试图获取不可用的锁时，会被阻塞，直到锁被释放

  - ```
    acquire()
    {
    	while(!available);	//忙等待
    	available = false;	//获得锁
    }
    release()
    {
    	available = true;	//释放锁
    }
    ```

  - acquire或release必须是原子操作，因此互斥锁通常采用硬件机制来实现

  - 互斥锁的主要缺点是忙等待，当有一个进程在临界区中，任何其他进程在进入临界区时必须连续循环调用acquire。当多个进程共享一个CPU时，就浪费了CPU的周期。因此，互斥锁通常用于多处理器系统，一个线程可用在一个处理机上等待，不影响其他线程的执行

  - 需要连续循环忙等的互斥锁，都可用称为自旋锁，如TSL指令、Swap指令、单标志法

  - 特性：

    - 需忙等，进程时间片用完才下处理机，违法放权等待
    - 优点：等待期间不用切换进程上下文，多处理器系统中，若上锁的时间短，则等待代价很低
    - 常用于多处理机系统，一个核忙等，其他核正常工作，并快速释放临界区
    - 不太适合用于单处理系统，忙等的过程中不可能解锁

  - ```
    do
    {
    	entry section;	//进入区	acquire()
    	cirtical section;	//临界区	
    	exit section;	//退出区	release()
    	remainder section;	//剩余区
    }while(true)
    ```

## （十五）信号量机制

- 信号量机制
  - 整型信号量
  - 记录型信号量
- 信号量机制：
  - 用户进程可以通过使用操作系统提供的一对原语来对信号量进程操作，从而很方便的实现了进程互斥、进程同步
  - 信号量其实就是一个变量（可以是一个整数，也可以是更复杂的记录型变量），可以用一个信号量来表示系统中某种资源的数量，比如：系统中只有一台打印机，就可以设置一个初值为1的信号量
  - 原语是一种特殊的程序段，其执行只能一气呵成、不可中断。原语是由关中断/开中断指令实现的。软件解决方案的主要问题是“进入区的各种操作无法一气呵成，因此如果能把进入区、退出区的操作都用原语实现，使这些操作能一气呵成，就能解决问题
  - 一对原语：wait(S)原语和signal(S)原语，可以把原语理解为我们自己写的函数，函数名分别为wait和signal，括号里的信号量S就是函数调用时传入的一个参数
  - wait、signal原语常简称P、V操作（来自荷兰语）。因此，做题时把wait(S)、signal(S)两个操作分别写作P(S)、V(S)

### 整型信号量

- 用一个整数型的变量作为信号量，用来表示系统中某种资源的数量

  - 注意：与普通整型变量的区别：对信号量只能执行初始化、P、V三种操作

  - ```
    //某计算机系统中有一台打印机
    int S = 1;	//初始化整型信号量，表示当前系统中可用的打印机资源数
    void wait(int S)	//wait原语，相当于进入区
    {
    	while(S <= 0);	//如果资源数不够，就一直循环等待
    	S = S - 1;	//如果资源数够，就占用一个资源
    }	//检查和上锁一气呵成，避免了并发、异步导致的问题	//存在的问题：不满足让权等待，会发生忙等
    void signal(int S)	//signal原语，相当于退出区
    {
    	S = S + 1;	//使用完资源后，在退出区释放资源
    }	
    进程P0
    ...
    wait(S);	//进入区，申请资源
    使用打印机资源	//临界区，访问资源
    signal(S);	//退出区，释放资源
    ...
    ```

### 记录型信号量

- 整型信号量的缺陷是存在忙等，因此人们又提出了记录型信号量，即用记录型数据结构表示的信号量

  - ```
    //记录型信号量的定义（单链表）
    typedef struct
    {
    	int value;	//剩余资源数
    	struct process *L;	//等待队列
    }semaphore;
    
    //某进程需要使用资源时，通过wait原语申请
    void wait(semaphore S)
    {
    	S.value--;
    	if(S.value < 0)
    	{
    		block(S.L);	//如果资源数不够，使用block原语使进程从运行态进入阻塞态，并把进程挂起到信号量S的等待队列中
    	}
    }
    
    //某进程使用完资源后，通过signal原语释放
    void signal(semaphore S)
    {
    	s.value++;
    	if(S.value <= 0)
    	{
    		wakeup(S.L);	//释放资源后，若还有别的进程在等待这种资源，则使用wakeup原语唤醒等待队列中的一个进程，该进程从阻塞态变为就绪态
    	}
    }
    
    ```

  - 对信号量S的一次P操作意味着进程请求一个单位的该类资源，因此需要执行S.value--，表示资源数减1，当S.value<0时表示该类资源已分配完毕，因此进程应调用block原语进程自我阻塞（当前运行的进程从运行态切换为阻塞态），主动放弃处理机，并插入该类资源的等待队列S.L中。可见，该机制遵循了让权等待原则，不会出现忙等现象

  - 对信号量S的一次V操作意味着进程释放一个单位的该类资源，因此需要执行S.value++，表示该资源数加1，若加1后仍是S.value <= 0，表示依然有进程在等待该类资源，因此应调用wakeup原语唤醒等待队列中第一个进程（被唤醒进程从阻塞态切换到就绪态）

## （十六）用信号量实现进程互斥同步、互斥和前驱关系

  - 信号量机制：
    - 实现进程互斥
    - 实现进程同步
    - 实现进程的前驱关系
  - 理解信号量背后的含义：
    - 一个信号量对应一种资源
    - 信号量的值 = 这种资源的剩余数量
    - P(S)：申请一个资源S，如果资源不够就阻塞等待
    - V(S)：释放一个资源S，如果有进程在等待该资源，则唤醒一个进程

  ### 信号量机制实现进程互斥

  1. 分析并发进程的关键活动，划分临界区（如：对临界资源打印机的访问就应放在临界区）
  2. 设置互斥信号量mutex，初值为1
  3. 在进入区P(mutex)：申请资源
  4. 在退出区V(mutex)：释放资源
     - 注意：
       - 对不同的临界资源需要设置不同的互斥信号量
       - P、V操作必须成对出现。缺少P就不能保证临界资源的互斥访问，缺少V会导致资源永不被释放

  ### 信号量机制实现进程同步

  - 进程同步：要让并发进程按要求有序推进
  - 用信号量机制实现进程同步：
    1. 分析什么时候需要实现同步关系，即必须保证一前一后执行的两个操作
    2. 设置同步信号量S，初始为0
    3. 在前操作之后执行V(S)
    4. 在后操作之后执行P(S)

  ### 信号量机制实现前驱关系

  - 每一对前驱关系都是一个进程同步问题（需要保证一前一后操作），因此：
    1. 要为每一对前驱关系各设置一个同步信号量
    2. 在前操作之后对对应的同步信号量执行V操作
    3. 在后操作之前对对应的同步信号量执行P操作

  ## （十七）生产者消费者问题

- 问题描述：

  - 系统中有一组生产者进程和一组消费者进程，生产者进程每次生产一个产品放入缓冲区，消费者进程每次从缓冲区中取出一个产品并使用。
  - 生产者、消费者共享一个初始为空、大小为n的缓冲区
  - 只有缓冲区没满时，生产者才能把产品放入缓冲区，否则必须等待（缓冲区没满->生产者生产）
  - 只有缓冲区不为空时，消费者才能从中取出产品，否则必须等待（缓冲区没空->消费者消费）
  - 缓冲区是临界资源，各进程必须互斥访问（互斥关系）

- PV操作题目分析步骤：

  1. 关系分析。找出题目中描述的各个进程，分析它们之间的同步、互斥关系
  2. 整理思路。根据各进程的操作流程确定P、V操作的大致顺序
  3. 设置信号量。并根据题目条件确定信号量初值。（互斥信号量初值一般为1，同步信号量的初值要看对应资源的初始值是多少）

- 代码实现：

  - ```c
    semaphore mutex = 1;	//互斥信号量，实现对缓冲区的互斥访问
    semaphore empty = n;	//同步信号量，表示对空闲缓冲区的数量
    semaphore full = 0;		//同步信号量，表示产品的数量，也即非空缓冲区的数量
    //生产者
    prodecer()
    {
        while(1)
        {
            生产一个产品;
            P(empty);	//消耗一个空闲缓冲区	//1
            P(mutex);	//2
            把产品放入缓冲区;
            V(mutex);
            V(full);	//增加一个产品
        }
    }
    //消费者
    consumer()
    {
        while(1)
        {
            P(full);	//消耗一个产品	//3
            P(mutex);	//4
            从缓冲区中取出一个产品;
            V(mutex);
            V(empty);	//增加一个空闲缓冲区
            使用产品;
        }
    }
    ```

- 思考：能否改变相邻P、V的操作？将上述1、2顺序互换，3、4顺序互换，会发生什么：

  - 若此时缓冲区内已经放满了产品，则empty = 0，full = n
  - 则生产者执行1使mutex变为0，再执行2，由于已经没有空闲缓冲区，因此生产者被阻塞
  - 由于生产者被阻塞，因此切换回消费者模式。消费者进程执行3，由于mutex为0，即生产者还未释放对临界资源的锁，因此消费者也被阻塞
  - 这就造成了生产者等待消费者释放空闲缓冲区，而消费者又等待生产者释放临界区的情况，生产者和消费者循环等待被对方唤醒，出现死锁
  - 同样的，若缓冲区中没有产品，此时执行3、4、1顺序也会发生死锁
  - 因此：实现互斥的P操作一定要在实现同步到P操作之后
  - 而V操作不会导致进程阻塞，因此两个V操作顺序可以交换


## （十八）多生产者-多消费者问题

- 问题描述：

  - 桌子上有一个盘子，每次只能向其中放入一个水果
  - 爸爸专门向盘子里放苹果，妈妈专向盘子里放橘子
  - 女儿专等着吃盘子里的苹果，儿子专等着吃盘子里的橘子
  - 只有盘子空时，爸爸或妈妈才可向盘子里放一个水果
  - 仅当盘子里有自己需要的水果时，女儿或儿子才可以从盘子中取出水果。
  - 用PV操作实现上述过程

- 问题分析：

  1. 关系分析，找出题目中描述的各个进程，分析它们之间的同步、互斥关系：

     - 互斥关系，对缓冲区（盘子）的访问要互斥进行
     - 同步关系：
       1. 父亲将苹果放入盘子后，女儿才能取苹果
       2. 母亲将橘子放入盘子后，儿子才能取橘子
       3. 只有盘子为空时，父亲或母亲才能放入水果
          - 盘子为空这个时间可以由儿子或女儿触发，事件发生后才允许父亲或母亲放水果

  2. 整理思路，根据各进程的操作流程确定P、V操作的大致顺序

  3. 设置信号量。并根据题目条件确定信号量初值。（互斥信号量初值一般为1，同步信号量的初值要看对应资源的初始值是多少）

     - ```
       semaphore mutex = 1;	//实现互斥访问盘子（缓冲区）
       semaphore apple = 0;	//盘子中有几个苹果
       semaphore orange = 0;	//盘子中还有几个橘子
       semaphore plate = 1;	//盘子中还可以放多少个水果（应该是可用的盘子数吧）
       ```

- 代码实现：

  - ```
    semaphore mutex = 1;	//实现互斥访问盘子（缓冲区）
    semaphore apple = 0;	//盘子中有几个苹果
    semaphore orange = 0;	//盘子中还有几个橘子
    semaphore plate = 1;	//盘子中还可以放多少个水果（应该是可用的盘子数吧）
    
    dad()
    {
    	while(1)
    	{
    		准备一个苹果;
    		P(plate);
    		P(mutex);
    		把苹果放入盘子;
    		V(mutex);
    		V(apple);
    	}
    }
    
    mom()
    {
    	while(1)
    	{
    		准备一个橘子;
    		P(plate);
    		P(mutex);
    		把橘子放入盘子;
    		V(mutex);
    		V(orange);
    	}
    }
    
    daughter()
    {
    	while(1)
    	{
    		P(apple);
    		P(mutex);
    		从盘子里取出苹果;
    		V(mutex);
    		V(plate);
    		吃掉苹果;
    	}
    }
    
    son()
    {
    	while(1)
    	{
    		P(orange);
    		P(mutex);
    		从盘子里取出橘子;
    		V(mutex);
    		V(plate);
    		吃掉橘子;
    	}
    }
    ```

  - 分析：

    - 本例中即使不设置专门的互斥变量mutex，也不会出现多个进程同时访问盘子的现象
      - 原因在于：本题中的缓冲区大小为1，在任何时刻，apple、orange、plate三个同步信号量中最多只有一个是1。因此在任何时刻，最多只有一个进程能顺利进入临界区
    - 而缓冲区如果大于1，就必须设置一个互斥信号量mutex来保证互斥访问缓冲区
      - 否则可能出现两个进程同时访问临界区，导致出现两个进程写入缓冲区的数据互相覆盖的情况

  ## （十九）吸烟者问题

  - 问题描述：

    - 假设一个系统有三个吸烟者进程和一个供应者问题。每个抽烟者不停地卷烟并抽掉它，但是要卷起并抽掉一包烟，抽烟者需要有三种材料：烟草、纸和胶水。三个抽烟者中，第一个拥有烟草、第二个拥有纸、第三个拥有胶水。供应者无限地提供三种材料，供应者每次将两种材料放在桌子上，拥有剩下那种材料的抽烟者卷一根烟并抽掉，并给供应者一个信号告诉完成了，供应者就会放另外两种材料在桌子上，这个过程一直重复（让三个抽烟者轮流抽烟）

  - 问题分析：

    - 桌子可以抽象为容量为1的缓冲区，要互斥访问
    - 同步关系：
      - 桌上有组合一（纸和胶水），第一个抽烟者取走东西
      - 桌上有组合二（烟草和胶水），第二个抽烟者取走东西
      - 桌上有组合一（纸和烟草），第三个抽烟者取走东西
      - 发出完成信号后，供应者提供下一个组合放到桌子上

  - 代码实现：

    - ```
      semaphore finish = 0;	//抽烟是否完成
      semaphore offer1= 0;	//桌上是否有组合一
      semaphore offer2 = 0;	//桌上是否有组合二
      semaphore offer3 = 1;	//桌上是否有组合三
      int i = 0;	//用于实现三个抽烟者轮流抽烟
      
      privider()
      {
      	while(1)
      	{
      		if(i == 0)
      		{
      			将组合一放桌上;
      			V(offer1);
      		}
      		else if(i == 1)
      		{
      			将组合二放桌上;
      			V(offer2);
      		}
      		else if(i == 2)
      		{
      			将组合三放桌上;
      			V(offer3);
      		}
      		i = (i + 1) % 3;
      		P(finish);	//完成一次后会阻塞，直到有一个抽烟者抽完并返回了完成信号
      	}
      }
      
      smoker1()
      {
      	while(1)
          {
          	P(offer1);
          	从桌上拿走组合一;
          	卷烟;
          	抽掉;
          	V(finish);
          }
      }
      
      smoker2()
      {
      	while(1)
          {
          	P(offer2);
          	从桌上拿走组合二;
          	卷烟;
          	抽掉;
          	V(finish);
          }
      }
      
      smoker3()
      {
      	while(1)
          {
          	P(offer3);
          	从桌上拿走组合三;
          	卷烟;
          	抽掉;
          	V(finish);
          }
      }
      ```

    - 分析：

      - 缓冲区大小为1，同一时刻，四个同步信号量中至多有一个的值为1，因此不需要设置一个专门的互斥信号量

    - 总结：若一个生产者要生产多种产品（或引发多种前驱事件），那么各个V操作应该放在各自对应的事件发生之后的位置

## （十九）读者-写者问题

- 问题描述：

  - 有读者写者两组并发进程，共享一个文件，当两个或两个以上的进程读进程同时访问共享数据时不会产生副作用，但若某个写进程和其他进程（读进程或写进程）同时访问共享数据时则可能导致数据不一致的错误。因此要求：
    - 允许多个读进程同时对文件执行读操作
    - 只允许一个写者往文件中写信息
    - 任一写者在完成写操作之前不允许其他读者或写者工作
    - 写者执行写操作之前，应让已有的读者和写者全部退出

- 问题分析：

  - 互斥关系：写进程与写进程、写进程和读进程（读进程和读进程之间不互斥）

- 如何实现：

  - ```
    semaphore rw = 1;	//用于实现对共享文件的互斥访问
    int count = 0;	//用于记录当前有几个读进程在访问文件
    semaphore mutex = 1;	//用于保证对count变量的访问是互斥的
    
    writer()
    {
    	while(1)
    	{
    		P(rw);	//写之前加锁
    		写文件...
    		V(rw);	//写完了解锁
    	}
    }
    
    reader()
    {
    	while(1)
    	{
    		P(mutex);	//各进程互斥访问count，并发的读进程必须等其他读进程对count的访问结束
    		if(count == 0)	//由第一个读进程负责加锁，其他读进程到这里会跳过加锁
    			P(rw);
    		count++;	访问文件的读进程数加一
    		V(mutex);
    		读文件...
    		P(mutex);
    		count--;	//读进程结束后减一
    		if(count == 0)
    			V(rw);	//最后一个读进程负责解锁
    		V(mutex);
    	}
    }
    ```

  - 分析：

    - 若没有互斥信号量时，两个并发的读进程执行时，count==0，两个进程都满足if条件，都会执行P(rw)，从而使第二个读进程阻塞。原因在于：count变量的检查和复制无法一气呵成，因此需要设置另一个互斥信号量来保证各进程对count的访问是互斥的
    - 潜在的问题：只要有读进程还在读，写进程就要一直阻塞等待，可能导致饿死。因此这种算法中，读进程是优先的

- 实现二（写进程优先）：

  - ```
    semaphore rw = 1;	//用于实现对共享文件的互斥访问
    int count = 0;	//用于记录当前有几个读进程在访问文件
    semaphore mutex = 1;	//用于保证对count变量的访问是互斥的
    semaphore w = 1;	用于实现写优先
    
    writer()
    {
    	while(1)
    	{
    		P(w);
    		P(rw);	//写之前加锁
    		写文件...
    		V(rw);	//写完了解锁
    		V(w);
    	}
    }
    
    reader()
    {
    	while(1)
    	{
    		P(w);
    		P(mutex);	//各进程互斥访问count，并发的读进程必须等其他读进程对count的访问结束
    		if(count == 0)	//由第一个读进程负责加锁，其他读进程到这里会跳过加锁
    			P(rw);
    		count++;	访问文件的读进程数加一
    		V(mutex);
    		V(w);
    		读文件...
    		P(mutex);
    		count--;	//读进程结束后减一
    		if(count == 0)
    			V(rw);	//最后一个读进程负责解锁
    		V(mutex);
    	}
    }
    ```

  - 分析：

    - 变量w有效避免了读进程源源不断进入时写进程无法执行的问题（例：读->写->读...），解决了写进程持续饥饿的问题
    - 在这种算法中，连续进入的多个读者可以读文件；写者和其他进程不能同时访问文件；写者不会饥饿，但也不是真正的写优先，而是相对公平的先来先服务。（可称，读写公平法）
    - 思考：如何实现真正的写优先

- 总结：

  - 解决复杂的互斥问题时，核心思想在于设置了一个计数器（count）来记录当前正在访问共享文件的读进程数。用count的值判断当前进入的进程是否是第一个/最后一个读进程，从而做出不同处理
  - 另外，对count变量的检查和赋值不能一气呵成导致了一些错误，如果需要实现一气呵成，采用了互斥信号量
  - 最后，体会如何解决写进程饥饿的问题

## （二十）哲学家进餐问题

- 问题描述：

  - 一张圆桌上坐了五位哲学家，每两位哲学家之间的桌子上摆一根筷子，桌子的中间是一碗米饭。哲学家们只进行思考或进餐两种活动，哲学家思考时，不影响他人。只有当哲学家饥饿时，才试图拿起左右两根筷子（一根一根拿起）。如果筷子已经在他人手上，则需等待。饥饿哲学家只有同时拿起两根筷子才可以开始进餐，当进餐结束后，放下筷子继续思考

- 问题分析：

  1. 关系分析：系统中有五个哲学家进程，五位哲学家与左右邻居对其中间筷子的访问是互斥的
  2. 整理思路：这个问题中只有互斥关系，但与之前遇到的问题不同，每个哲学家进程需要同时持有两个临界资源才能开始吃饭。思考如何避免临界资源分配不当而造成死锁
  3. 信号量设置：定义互斥信号量数组chopstick[5]={1,1,1,1,1}用于实现对五根筷子的互斥访问。并对哲学家按0~4编号，哲学家左边的筷子编号为 i ，右边的筷子编号为 (i+1)%5

- 问题实现：

  - ```
    semaphore chopstick[5] = {1,1,1,1,1};
    Pi()	//第i号哲学家的进程
    {
    	while(1)
    	{
    		P(chopstick[i]);	//拿左
    		P(chopstick[(i+1)%5]);	//拿右
    		吃饭...
    		V(chopstick[i]);	//放左
    		V(chopstick[(i+1)%5]);	//放右
    		思考...
    	}
    }
    ```

  - 分析：

    - 如果五个哲学家并发地拿起自己左手边的筷子，则每位哲学家将循环等待右边的人放下筷子（阻塞），发生死锁

    - 如何避免死锁发生：

      1. 可以对哲学家进程施加一些限制条件，比如最多允许四个哲学家同时进餐。这样就可以保证至少有一个哲学家是可以同时拿到左右两只筷子的

         - 可以设置一个初始值为4的同步信号量

      2. 要求奇数号哲学家先拿左边的筷子。如何再拿右边的筷子，而偶数号哲学家刚好相反。用这种方法可以保证如果相邻的两个哲学家都想吃饭，那么只会有其中一个可以拿起第一根筷子，另一个会之间阻塞。这就避免了占有一根后再等待另一根的情况

         - 可以在每个哲学家拿筷子前先判断编号的奇偶，再做出不同判断

      3. 同时只有一个人可以开始拿筷子

         - 设置一个互斥信号量，在拿筷子前后执行PV操作

           - ```
             semaphore chopstick[5] = {1,1,1,1,1};
             semaphore mutex = 1;	//互斥地取筷子
             Pi()	//第i号哲学家的进程
             {
             	while(1)
             	{
             		P(mutex);
             		P(chopstick[i]);	//拿左
             		P(chopstick[(i+1)%5]);	//拿右
             		V(mutex);
             		吃饭...
             		V(chopstick[i]);	//放左
             		V(chopstick[(i+1)%5]);	//放右
             		思考...
             	}
             }
             ```

- 总结：

  - 哲学家进餐问题的关键在于：解决进程死锁
  - 这些进程之间只存在互斥关系，但是与之前解除的互斥关系不同的是，每个进程都需要同时持有两个临界资源，因此就有死锁问题
  - 如果一个进程需要多个临界资源，则应参考哲学家进餐问题，分析进进程之间是否会发生循环等待，是否会发生死锁

## （二十一）管程

- 管程：

  - 为什么要引入管程
  - 管程的定义和基本特征
  - 拓展1：用管程解决生产者消费者问题
  - 拓展2：Java中类似于管程的机制

- 为什么要引入管程：

  - 信号量机制存在的问题：编写程序困难、易出错
  - 能不能设置一种机制，让程序员编写程序时不需要再关注复杂的PV操作
  - 1973年，首次在程序设计语言（Pascal）中引入“管程”成分 --- 一种高级同步机制

- 管程的定义和基本特征：

  - 管程（类似于面向对象程序设计语言中的类），是一种特殊的软件模块，有以下部分组成：
    1. 局部于管程的共享数据结构说明
    2. 对该数据结构的一组过程（函数）
    3. 对局部于管程的共享数据结构设置初始值的语句（初始化）
    4. 管程有一个名字
  - 管程的特征：
    1. 局部于管程的数据只能被局部于管程的过程所访问
    2. 一个进程只有通过管程内的过程才能进入管程访问共享数据
    3. 每次仅允许一个进程在管程内执行某个内部过程

- 拓展1：用管程解决生产者消费者问题

  - ```
    monitor ProdecerConsumer	//管程名称
    	condition full,empty;	//条件变量用来实现同步	//可在管程中设置条件变量及等待/唤醒操作以解决同步问题
    	int count = 0;	//缓冲区中的产品数
    	void insert(Item item)	//把产品放入缓冲区	//由编译器负责实现进程互斥地进入管程中的过程
    	{
    		if(count == N)
    			wait(full);
    		count++;
    		insert_item(item);
    		if(count == 1)
    			signal(empty);
    	}
    	Item remove()	//从缓冲区中取出一个产品
    	{
    		if(count == 0)
    			wait(empty);
    		count--;
    		if(count == N-1)
    			signal(full);
    		return remove_item();
    	}
    end monitor;
    
    //生产者进程
    producer()
    {
    	while(1)
    	{
    		item = 生产一个产品;
    		ProducerConsumer.insert(item);
    	}
    }
    
    //消费者进程
    comsumer()
    {
    	while(1)
    	{
    		item = ProducerConsumer.remove();
    		消费产品item;
    	}
    }
    ```

  - 引入管程的目的：更方便地实现进程互斥和同步

    - 需要在管程中定义共享数据（如：生产者消费者问题中的缓冲区）
    - 需要在管程中定义用于访问这些共享数据的入口，其实就是一些函数（如：生产者消费者问题中，可以定义一个函数用于将产品放入缓冲区，再定义一个函数用于从缓冲区中取出产品）
    - 只有通过特定的入口才能访问共享数据
    - 管程中有很多入口，但是每次只能开放其中一个入口，并且只能让一个进程或线程进入（如：生产者消费者问题中，各进程需要互斥地访问共享缓冲区。管程的这种特性即可保证一个时间段内最多只会有一个进程在访问缓冲区。注意：这种互斥特性是由编译器负责实现的，程序员不用关心）
    - 可在管程中设置条件变量及等待/唤醒操作以解决同步问题。可以让一个进程或线程在条件变量上等待（此时，该进程应先释放管程的使用权，也就是让出“入口”）；可以通过唤醒操作将等待在条件变量上的进程或线程唤醒

  - 程序员可以用某种特殊的语法定义一个管程（比如：monitor Producer Consumer...end monitor），之后程序员就可以使用这个管程提供的特定“入口”很方便地使用进同步/互斥

- 拓展2：Java中类似于管程的机制：

  - Java中，如果用关键字synchronized来描述一个函数，那么这个函数同一时间只能被一个线程调用

# 三.死锁

## （一）死锁的概念

- 死锁的概念
  - 什么是死锁
  - 进程死锁、饥饿、死循环的区别
  - 死锁产生的必要条件
  - 什么时候会发生死锁
  - 死锁的处理策略

### 什么是死锁

- 在并发环境下，各进程因竞争资源而造成的一种互相等待对方手里资源，导致各进程都阻塞，都无法向前推进的现象，就是死锁。
  - 发生死锁后，若无外力干涉，这些进程都将无法向前推进

### 进程死锁、饥饿、死循环的区别

- 死锁：各进程因竞争资源而造成的一种互相等待对方手里资源，导致各进程都阻塞，都无法向前推进的现象
- 饥饿：由于长期得不到想要的资源，某进程无法向前推进的现象。比如：在短进程优先算法（SPF）中，若有源源不断的短进程到来，则长进程将一直得不到处理机，从而发生长进程饥饿
- 死循环：某进程执行的过程中一直跳不出来某个循环的现象。有时是因为程序逻辑bug导致，有时是程序员故意设置的

- 共同点：
  - 都是进程无法顺利向前推进的现象（故意设计的死循环除外）
- 区别：
  - 死锁：一定是循环等待对方手里的资源导致的，因此，如果有死锁现象，则至少有两个或两个以上的进程同时发生死锁。另外，发生死锁的进程一定处于阻塞态
  - 饥饿：可能只有一个进程发生饥饿。发生饥饿的进程既可能是阻塞态（如长期得不到需要的IO设备），也可能是就绪态（长期得不到处理机）
  - 死循环：可能只有一个进程发生死循环。死循环的进程可以上处理机（可以是运行态），只不过无法像期待的那样顺利推进。死锁和饥饿问题是由于操作系统分配资源的策略不合理导致的，而死循环是由代码逻辑错误导致的。死锁是管理者（操作系统）的问题，而死循环是被管理者的问题

### 死锁产生的必要条件

- 产生死锁必须同时满足以下四个条件（只要任一条件不成立，死锁就不会发生）：
  1. 互斥条件：只有对必须互斥使用的资源才会导致死锁（如哲学家的筷子、打印机设备）。像内存、扬声器这样可以同时让多个进程使用的资源是不会导致死锁的（因为进程不用阻塞等待）
  2. 不剥夺条件：进程所获得的资源在未使用完之前，不能由其他进程强行夺走，只能主动释放
  3. 请求和保持条件：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源又被其他进程占有，此时请求进程被阻塞，但又对自己已有的资源保持不放
  4. 循环等待条件：存在一种进程资源的循环等待链，链中的每一个进程已获得的资源同时被下一个进程所请求
     - 注意：发生死锁时一定有循环等待，但发生循环等待时未必死锁（循环等待是死锁的必要不充分条件）。如果同类资源数大于1，则即使有循环等待，也未必发生死锁。但如果系统中每类资源都只有一个，那循环等待就是死锁的充分必要条件

### 什么时候会发生死锁

1. 对系统资源的竞争。各进程对不可剥夺的资源（如打印机）的竞争可能引起死锁，对可剥夺的资源（CPU）的竞争是不会引起死锁的
2. 进程推进顺序非法。请求和释放资源的顺序不当，也同样会导致死锁。例如，并发执行的进程P1、P2分别申请并占有了资源R1、R2，之后进程P1又紧接着申请资源R2，而进程P2又申请R1，两者会因为申请的资源被对方占有而阻塞，从而发生死锁
3. 信号量的使用不当也会造成死锁。如生产者消费者问题中，如果实现互斥的P操作在实现同步的P操作之前，就可能会导致死锁。（可以把互斥信号量、同步信号量也看作是一种抽象的系统资源

- 总之，对不可剥夺的资源的不合理分配，可能导致死锁

### 死锁的处理策略

1. 预防死锁（静态策略）。（不允许死锁发生）破坏死锁产生条件中的一个或几个
2. 避免死锁（动态策略）。（不允许死锁发生）用某种方法防止系统进入不安全系统，从而避免死锁（银行家算法）
3. 死锁的检测和解除。允许死锁的发生，不过操作系统会负责检测出死锁的发生，然后采取某种措施解除死锁

## （二）死锁的处理策略（预防死锁）

- 静态策略：预防死锁
  - 破坏互斥条件
  - 破坏不剥夺条件
  - 破坏请求和保持条件
  - 破坏循环等待条件
### 破坏互斥条件
  - 互斥条件：只有对必须互斥使用的资源的争抢才会导致死锁
  - 如果把只能互斥使用的资源改造为允许共享使用，则系统不会进入死锁，比如：SPOOLing技术。操作系统可以采用SPOOLing技术把独占设备在逻辑上改造成共享设备。比如：用SPOOLing技术将打印机改造为共享设备
  - 该策略的缺点：并不是所有资源都可以改造成可共享使用的资源。并且为了系统安全，很多对方还必须保护这种互斥性。因此，很多时候都无法破坏互斥条件
### 破坏不剥夺条件
  - 不剥夺条件：进程所获得的资源在未使用完之前，不能由其他进程强行夺走，只能主动释放
  - 破坏不剥夺条件的方案：
    - 方案一：当某个进程请求新的资源得不到满足时，它必须立即释放保持的所有资源，待以后需要时再重新申请。也就是说，即使某些资源尚未使用完，也需主动释放，从而破坏了不可剥夺条件
    - 方案二：当某个进程需要的资源被其他进程所占有的时候，可以由操作系统协助，将想要的资源强行剥夺。这种方式一般需要考虑各进程的优先级（比如：剥夺调度方式，就是将处理机资源强行剥夺给优先级更高的进程使用）
  - 该策略的缺点：
    1. 实现起来比较复杂
    2. 释放已获得的资源可能导致前一阶段的工作失效。因此这种方法只适用于易保存和恢复状态的资源，如CPU
    3. 反复地申请和释放资源会增加系统开销，降低系统吞吐量
    4. 若采用方案一，意味着只要暂时得不到某个资源，之前获得的那些资源就都要放弃，以后重新申请。如果一直发生这种情况，就会导致进程饥饿

### 破坏请求和保持条件

- 请求和保持条件：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源又被其他进程占有，此时请求进程被阻塞，但又对自己已有的资源保持不放
- 可以采用静态分配方法，即进程在运行前一次申请完它所需要的全部资源，在它的资源未满足前，不让它投入运行。一旦投入运行后，这些资源就一直归他所有，该进程就不会再请求别的资源了
- 该策略实现起来简单，但也有明显的缺点：
  - 有些资源可能只需要用很短的时间，因此如果进程的整个运行期间都一直保持着所有的资源，就会造成严重的资源浪费，资源利用率极低。另外，该策略也可能导致某些进程饥饿

### 破坏循环等待条件

- 循环等待条件：存在一种进程资源的循环等待链，链中的每一个进程已获得的资源同时被下一个进程所请求
- 可采用顺序资源分配法。首先给系统中的资源编号，规定每个进程必须按编号递增的顺序请求资源，同类资源（即编号相同的资源）一次申请完
  - 原理分析：一个进程只有已占有小编号的资源时，才有资格申请更大编号的资源。按此规则，已持有大编号资源的进程不可能逆向地回来申请小编号的资源，从而不会产生循环等待的现象
  - 在任何一个时刻，总有一个进程拥有的资源编号是最大的，那这个进程申请之后的资源必然畅通无阻。因此，不可能出现所有进程都阻塞的死锁现象
- 该策略的缺点：
  - 不方便增加新的设备，因为可能需要重新分配所有的编号
  - 进程实际使用资源的顺序可能和编号递增顺序不一样，会导致资源浪费
  - 必须按规定次序申请资源，用户编程麻烦

## （三）死锁的处理策略（避免死锁）

- 动态策略：避免死锁

  - 什么是安全序列
  - 什么是系统的不安全状态，与死锁有何联系
  - 如何避免系统进入不安全状态（银行家算法）

### 什么是安全序列：

  - 安全序列：就是指如果系统按照这种序列分配资源，则每个进程都能顺利完成。只要能找出一个安全序列，系统就是安全状态。安全序列可能有多个

### 什么是系统的不安全状态，与死锁有何联系

  - 如果系统分配了资源之后，系统中找不出任何一个安全序列，系统就进入了不安全状态。这就意味着之后所有进程都无法顺利执行下去。当然，如果有进程提前归还了一些资源，那系统也有可能重新回到安全状态，不过我们在分配资源之前总是要考虑到最坏的情况
  - 如果系统处于安全状态，就一定不会发生死锁。如果系统进入不安全状态，就可能发生死锁（但不是一定发生死锁）
  - 因此可以在资源分配之前预先判断这次分配是否会导致系统进入不安全状态，以此决定是否答应资源分配请求。这也是银行家算法 的核心思想

### 银行家算法：

  - 核心思想：

    - 在进程提出资源申请时，先预判此次分配是否会导致系统进入不安全状态。如果会进入不安全状态，就暂时不答应此次请求，让该进程先阻塞等待

  - 思考：计算机中有多种资源，如何把算法拓展为多种资源的情况？

    - 可以把单维的资源拓展为多维的向量。比如：系统中有5个进程P0~P4，3中资源R0~R2，初始数量为（10，5，7），则某一时刻的情况如下表：

    - | 进程 |  最大需求   |   已分配    | 最多还需要  |
      | :--: | :---------: | :---------: | :---------: |
      |  P0  | （7，5，3） | （0，1，0） | （7，4，3） |
      |  P1  | （3，2，2） | （2，0，0） | （1，2，2） |
      |  P2  | （9，0，2） | （3，0，2） | （6，0，0） |
      |  P3  | （2，2，2） | （2，1，1） | （0，1，1） |
      |  P4  | （4，3，3） | （0，0，2） | （4，3，1） |

    - 资源总数（10，5，7），已用资源（7，2，5），剩余可用资源（3，3，2）

    - 此时系统是否处于安全状态？

      - 思路：尝试找出一个安全序列（依次检查剩余可用资源（3，3，2）是否能满足各进程需求
      - 第一轮：
        - 从P0开始，P0不可以
        - P1可以，将P1加入安全序列，并更新剩余可用资源值为（5，3，2）
      - 第二轮：
        - 再从P0开始，P0不可以，P2不可以
        - P3可以，将P3加入安全序列，并更新剩余可用资源值为（7，4，3）
      - 第三轮：
        - 从P0开始，P0可以，将P0加入安全序列，并更新剩余可用资源值为（7，5，3）
      - 第四轮：
        - 从P2开始，P2可以，将P2加入安全序列，并更新剩余可用资源值为（10，5，5）
      - 第五轮：
        - 从P4开始，P4可以，将P4加入安全序列，并更新剩余可用资源值为（10，5，7）
      - 经过五次循环检查即可将5个进程都加入安全序列，最终可得一个安全序列。该算法称为安全性算法。可以很方便地用代码实现以上流程，每一轮检查都从编号较小的进程开始检查。
      - 实际做题时可以更快速地得到安全序列：
        - 经对比发现，P1、P3可满足，可以之间将P1、P3加入安全序列，更新剩余可用资源值为（7，4，3）
        - 之后，P0、P2、P4都满足，则可全部加入安全序列
        - 于是，5个进程全部加入安全序列，说明此时系统处于安全状态，赞不可能发生死锁
      - 若某题中，剩余可用资源无法满足任何一个进程，无法找到任何一个安全序列，说明此时系统处于不安全状态，有可能发生死锁

  - 银行家算法代码逻辑：

    - 假设系统中有n个进程，m种资源
    - 每个进程在运行前先声明对各种资源的最大需求数，则可用一个 `n*m` 的矩阵（可用二维数组实现）表示所有进程对各种资源的最大需求树。不妨称为最大需求矩阵Max，Max[ i , j ] = K 表示进程Pi最多需要 K 个资源 Rj 。同理，系统可用用一个 `n*m` 的分配矩阵 Allocation 表示对所有进程的资源分配情况。Max - Allocation = Need 矩阵，表示各进程最多还需要多少各类资源
    - 另外，还需要用一个长度为 m 的一维数组 Available 表示当前系统中还有多少可用资源
    - 某进程 Pi 向系统中申请资源，可用一个长度为 m 的一维数组 Request<sub>i</sub> 表示本次申请的各种资源量
    - 可用银行家算法预判本次分配是否会导致系统进入不安全状态：
        1. 如果 Request<sub>i</sub> [ j ] <= Need[ i , j ]	(0 <= j <= m)，转向2；否则认为出错（此次需要的资源超出原本声明的最大值）
        2. 如果 Request<sub>i</sub> [ j ] <= Available[ i , j ]	(0 <= j <= m)，转向3；否则 表示 尚无足够资源，Pi 必须等待
        3. 系统试探着把资源分配给进程 Pi，并修改相应的数据（并非真的分配，而只是做了预判）：
           - 更改可用资源：Available = Available - Request<sub>i</sub> 
           - 更改进程 Pi 的已分配资源：Available[ i , j ] = Available[ i , j ] + Request<sub>i</sub> 
           - 更改进程 Pi 的剩余所需最大资源：Need[ i , j ] = Need[ i , j ] - Request<sub>i</sub> 
        4. 操作系统执行安全性算法，检查此次资源分配后，系统是否处于安全状态。若安全，才正式分配；否则，恢复相应数据，让进程阻塞等待

  - 银行家算法步骤总结：

    1. 检查此次申请是否超过了之前声明的最大需求数
    2. 检查此时系统剩余的可用资源是否还能满足这次请求
    3. 试探分配，更改数据结构
    4. 用安全性算法检查此次分配是否会导致系统进入不安全状态
       - 安全性算法步骤：检查当前的剩余可用资源是否能满足某个进程的最大需求，如果可用，就把该进程加入安全序列，并把该进程持有的资源全部回收；不断重复上述过程，看最终能否让所有进程都加入安全序列

##  （四）死锁的处理策略（死锁的检测和解除）

- 死锁的检测和解除
  - 死锁的检测
  - 死锁的解除
- 如果系统中既不采取预防死锁的措施，也不采取避免死锁的措施，系统就很可能发生死锁。在这种情况下，系统应当提供两个算法：
  - 死锁检测算法：用于检测系统状态，以确定系统中是否发生了死锁
  - 死锁解除算法：当认定系统中已经发生了死锁，利用该算法可将系统从死锁状态中解脱出来

### 死锁的检测

- 为了能对系统是否已经发生了死锁进行检测，必须：
  - 用某种数据结构来保持资源的请求和分配信息
  - 提供一种算法，利用上述信息来检测系统是否已经进入死锁
- 资源分配图：
  - 两种结点：
    - 进程结点：对应一个进程
    - 资源结点：对应一类资源，可能有多个
  - 两种边：
    - 进程结点->资源结点：表示进程想申请几个资源（每条边代表一个）
    - 资源结点->进程结点：表示已经为进程分配了几个资源（每条边代表一个）
- 如果系统中剩余的可用资源数足够满足进程的需求，那么这个进程暂时不会阻塞，可用顺利执行下去。那么这个进程执行结束后把资源归还系统，就可能使某些正在等待资源的进程被激活，并顺利执行下去。相应的，这些被激活的进程执行完之后又会归还一些资源，这样可能又会激活另外一些阻塞的进程。如果按上述过程分析，最终能消除所有边，就称这个图是可完全简化的。此时一定没有发生死锁（相当于能找到一个安全序列）。如果不能消除所有边，那么此时就是发生了死锁。最终还连着边的那些进程就是处于死锁状态的进程
- 检测死锁的算法：
  - 在资源分配图中，找出既不阻塞也不是孤点的进程 Pi （即找出一条有向边与它相连，且该有向边对应的资源的申请数量小于等于系统中已有空闲资源数量）。消去它的所有请求边和分配边，使之称为孤立的结点。
  - 进程 Pi 所释放的资源，可以唤醒某些因等待这些资源而阻塞的进程，原理的阻塞进程可能变为非阻塞进程。若能根据1中方法消去途中所有的边，则称该图是可完全简化的
- 死锁定理：
  - 如果某时刻系统的资源分配图是不可完全简化的，那么此时系统死锁

### 死锁的解除

- 一旦检测出死锁的发生，就应该立即解除死锁
  - 并不是系统中所有进程都是死锁状态，用死锁检测算法化简资源分配图后，还连着边的那些进程就是死锁进程
- 解除死锁的方法：
  1. 资源剥夺法。挂起（暂时放到外存上）某些死锁进程，并抢占它的资源，将这些资源分配给其他的死锁进程。但是防止被挂起的进程长时间得不到资源而饥饿
  2. 撤销进程法（或终止进程法）。强制撤销部分、甚至全部死锁过程，并剥夺这些进程的资源，这种方法的优点是实现简单，但所付出的代价可能会很大。因为有些进程可能已经运行很长时间，已经接近结束，一旦终止可谓功亏一篑之后只能从头再来
  3. 进程回退法。让一个或多个死锁进程回退到足以避免死锁的地步。这就要求系统要记录进程的历史信息，设置还原点
     - 如何决定对谁动手：
       - 进程优先级
       - 已执行时间
       - 还需要多长时间
       - 进程已经使用了多少资源
       - 进程是交互式还是批处理式

# 四.内存管理

## （一）内存的基础知识

- 内存的基础知识
  - 什么是内存，有何作用
  - 进程运行的基本原理
    - 指令的工作原理
    - 逻辑地址和物理地址
    - 如何实现地址转换
    - 从写程序到程序运行的过程
- 什么是内存，有何作用
  - 内存可存放数据。程序执行前需要先放到内存中才能被CPU处理 ，缓和CPU与硬盘之间的矛盾
- 如何区分各个数据是放在什么地方呢？
  - 内存地址从0开始，每个地址对应一个存储单元
  - 如果计算机按字节编址，则每个存储单元为1字节，即1B，即8个二进制位
  - 如果计算机按字编制，则每个存储单元为一个字，每个字的大小不同的计算机可能不同
- 几个常用的数量单位：
  - 2<sup>10</sup> = 1K（千）
  - 2<sup>20</sup> = 1M（兆，百万）
  - 2<sup>30</sup> = 1G（十亿，千兆）
- 指令的工作原理
- 逻辑地址和物理地址

  - 程序经过编译、链接后生成的指令中指明的是逻辑地址，即：相对于进程的起始地址而言的地址
- 如何实现地址转换（三种装入方式）

  1. 绝对装入
     - 在编译时，如果知道程序将放到内存中的哪个位置，编译程序将产生绝对地址的目标代码。装入程序按照装入模块中的地址，将程序和数据装入内存
     - 绝对装入只适用于单道程序环境，此时还没产生操作系统
  2. 可重定位装入（静态重定位）
     - 又称可重定位装入。编译、链接后的装入模块的地址都是从0开始，指令中使用的地址、数据存放的地址都是相对于起始地址而言的逻辑地址。可根据内存的当前情况，将装入模块装入到内存的适当位置。装入时对地址进程重定位，将逻辑地址变换为物理地址
     - 静态重定位的特点是，在一个作业装入内存时，必须分配其要求的全部内存空间，如果没有足够的内存，就不能再装入该作业。作业一旦进入内存后，在运行期间就不能再移动，也不能再申请内存空间
     - 用于早期的多道批处理系统
  
  3. 动态运行时装入（动态重定位）
     - 又称动态运行时装入。编译、链接后的装入模块的地址都是从0开始的。装入程序把装入模块装入内存后，并不会立即把逻辑地址换为物理地址，而是把地址推迟到程序真正要执行时才进行。因此装入内存后所有的地址依然是逻辑地址。这种方式需要一个重定位寄存器的支持
     - 采用动态重定位时允许程序在内存中发生移动
     - 并且可将程序分配到不连续的存储区中；在程序运行前只需装入它的部分代码即可投入运行，然后再程序运行期间，根据需要动态申请分配内存；便于程序的共享，可以想用户提供一个比存储空间大得多的地址空间
     - 现代操作系统
- 从写程序到程序运行的过程
  - 编辑源代码文件
  - 编译：由编译程序将用户源代码编译成若干个目标模块（编译就是把高级语言翻译成机器语言）
  - 链接：由链接程序将编译后形成的一组目标模块，以及所需库函数链接在一起，形成一个完成的装入模块
  - 装入（装载）：由装入程序将装入模块装入内存运行
- 链接的三种方式
  1. 静态链接：在程序运行之前，先将各目标模块及它们所需的库函数连接成一个完整的可执行文件（装入模块），之后不再拆开
  2. 装入时动态链接：将各目标模块装入内存时，边装入边链接的链接方式
  3. 运行时动态链接：在程序执行中需要该目标模块时，才对它进行链接。其优点是便于修改和更新，便于实现对目标模块的共享

## （二）内存管理的概念

1. 操作系统负责内存空间的分配和回收（传统存储管理）
   - 连续分配管理方式：为用户进程分配的必须是一个连续的内存空间
     - 单一连续分配
     - 固定分区分配
     - 动态分区分配
   - 非连续分配管理方式：为用户进程分配的可以是一些分散的内存空间
     - 基本分页存储管理
     - 基本分段存储管理
     - 段页式存储管理
2. 操作系统需要提供某些技术从逻辑上对内存空间进行扩充
   - 覆盖技术
   - 交换技术
   - 虚拟存储技术
3. 操作系统需要提供地址转换功能，负责程序段逻辑地址与物理地址的转换
   - 三种装入方式
4. 操作系统需要提供内存保护功能。保证各进程在各自存储空间内运行，互不干扰。内存保护采取的两种方法：
   1. 在CPU中设置一对上下限寄存器，存放进程的上下限。进程的指令要访问某个地址时，CPU检查是否越界
   2. 采用重定位寄存器（又称基址寄存器）和界地址寄存器（又称限长寄存器）进行越界检查。重定位寄存器中存放的是进程的起始物理地址。界地址寄存器中存放的是进程的最大逻辑地址

## （三）覆盖与交换

### 覆盖技术

- 用来解决程序大小超过物理内存总和的问题

- 覆盖技术的思想：将程序分为多个段（多个模块）。常用的段常驻内存，不常用的段在需要时调入内存

  - 内存中分一个固定去和若干个覆盖区

  - 需要常驻的段放在固定区中，调入后就不再调出（除非运行结束）
  - 不常用的段放在覆盖区，需要用到时调入内存，用不到是调出内存
    - 按照自身逻辑结构，让那些不可能同时访问到的程序段共享同一个覆盖区

  - 覆盖结构必须由程序员声明，操作系统完成自动覆盖
    - 缺点：对用户不透明，增加了用户编程负担

- 覆盖技术只用于早期操作系统，现在已成为历史

### 交换(swapping)技术

- 交换技术的设计思想：内存空间紧张时，系统将内存中某些进程暂时换出外存，把外存中某些已具备运行条件的进程换入内存（进程在内存与磁盘间动态调度）
- 应该在外存（磁盘）的什么位置保存被换出的进程？
  - 具有对换功能的操作系统中，通常把磁盘空间分为文件区和对换区两部分。文件区主要用于存放文件，主要追求存储空间的利用率，因此对文件区空间的管理采用离散分配方式。对于对换的速度直接影响到系统的整体速度，因此对换空间的管理主要追求换入换出速度，因此通常对换区采用连续分配方式（文件管理章节）。总之，对换区的IO速度比文件区更快
- 什么时候应该交换？
  - 交换通常在许多进程运行且内存吃紧时进行，而系统负荷降低就暂停。例如：在发现许多进程运行时经常发生缺页，就说明内存紧张，此时可以换出一些进程；如果缺页率明显下降，就可以暂停换出
- 应该换出哪些进程？
  - 可优先换出阻塞进程；可换出优先级低的进程；为了防止优先级低的进程在被调入内存后很快又被换出，有的系统还会考虑进程在内存的驻留时间。（注意：PCB会常驻内存，不会被换出外存）

## （四）连续分配管理方式

- 连续分配：指为用户进程分配的必须是一个连续的内存空间

### 单一连续分配

- 在单一连续分配方式中，内存被分为系统区和用户区
  - 系统区通常位于内存的低地址部分，用于存放操作系统相关数据
  - 用户区用于存放用户进程相关数据
  - 内存中只能有一道用户程序，用户程序独占整个用户区空间
- 优点：
  - 实现简单
  - 无外部碎片
  - 可以采用覆盖技术扩充内存
  - 不一定需要采取内存保护（早期的PC操作系统MS-DOS）
- 缺点：
  - 只能用于单用户、单任务的操作系统
  - 有内部碎片（分配给某进程的内存区域中，如果有些部分没有用上，就是内存碎片）
  - 存储器利用率极低

### 固定分区分配

- 20世纪60年代出现了支持多道程序的系统，为了能在内存中装入多道程序，且这些程序之间又不会互相干扰，于是将整个用户空间划分为若干个固定大小的分区，在每个分区中只装入一道作业，这就形成了最早的、最简单的一种可运行多道程序的内存管理方式
- 固定分区分配：
  - 分区大小相等：缺乏灵活性，但是很适合用于用一台计算机控制多个相同对象的场合
  - 分区大小不相等：增加了灵活性，可以满足不同大小的进程需求。根据常在系统中运行的作业大小情况进行划分（比如：划分多个小分区、适量中等分区、少量大分区）
    - 操作系统需要建立一个数据结构：分区说明表，来实现各个分区的分配与回收。每个表项对于一个分区，通常按分区大小排列。每个表项包括对应分区的大小、起始排列、状态（是否已分配）。用数据结构的数组或链表即可表示这个表。当某用户要装入内存时，由操作系统内核程序根据用户大小检索该表，从中找到一个能满足大小的、未分配的分区，将之分配给该程序，然后修改状态为已分配
    - 优点：实现简单，无外部碎片
    - 缺点：
      - 当用户程序太大时，可能所有的分区都不能满足需求，此时不得不采用覆盖技术来解决，但这又会降低性能
      - 会产生内部碎片，内存利用率低

### 动态分区分配

- 动态分区分配又称为可变分区分配。这种分配方式不会预先划分内存分区，而是在进程装入内存时，根据进程的大小动态地建立分区，并使分区大小正好适合进程的需要。因此系统分区的大小和数目是可变的
- 思考：
  - 系统要用什么样的数据结构记录内存的使用情况？
    - 两种常用的数据结构：
      - 空闲分区表：每一个空闲分区对应一个表项。表项中包含分区号、分区大小、分区起始地址等信息
      - 空闲分区链：每个分区的起始部分和末尾部分分别设置前向指针和后向指针。起始部分还可记录分区大小等信息
  - 当很多各空闲分区都能满足需求时，应选择哪个分区进行分配？
    - 应该用最大的分区进行分配？还是用最小的分区进行分配？还是用地址最低的部分进行分配？把一个新作业装入内存时，须按照一定的动态分区分配算法，从空闲分区表中选出一个分区分配给该作业。由于分配算法对系统性能有很大影响，因此人民对它进行了广泛研究（四种动态分配算法）
  - 如何进行分区的分配和回收？
    - 分配（空闲分区表）：
      - 情况一：放在大小大于新进程的空闲分区
        - 修改空闲分区的大小和起始地址，表项个数不变
      - 情况二：放在大小等于新进程的空闲分区
        - 表项个数减少一个
    - 回收（空闲分区表）：
      - 情况一：回收区后面有一个相邻的空闲分区
        - 两个空闲分区合二为一，修改空闲分区的大小和起始地址，表项个数不变
      - 情况二：回收区前面有一个相邻的空闲分区
        - 两个空闲分区合二为一，修改空闲分区的大小和起始地址，表项个数不变
      - 情况三：回收区前后各有一个相邻的空闲分区
        - 三个空闲分区合二为一，修改空闲分区的大小和起始地址，减少一个表项
      - 情况四：回收区前后没有相邻的空闲分区
        - 新增一个表项
    - 注意：各表项的顺序不一定按照地址递增排列，具体的排列方式需要依据动态分区分配算法来确定
- 动态分区分配没有内部碎片，但是有外部碎片
  - 内部碎片：分配给某进程的内存区域中，如果有些部分没有用上
  - 外部碎片：是指内存中的某些空闲分区由于太小而难以利用
- 如果内存中空闲空间的总和本来可以满足某进程的要求，但由于进程需要的是一整块连续的内存空间，因此这些碎片不能满足进程的需求。可以通过紧凑技术来解决外部碎片

## （五）动态分区分配算法

- 动态分区分配算法：在动态分区分配方式中，当很多个空闲分区都能满足需求时，应该选择哪个分区进行分配？
  - 首次适应算法（First Fit）
  - 最佳适应算法（Best Fit）
  - 最坏适应算法（Worst Fit）
  - 邻近适应算法（Next Fit）

### 首次适应算法

- 算法思想：每次都从低地址开始查找，找到第一个能满足大小的空闲分区
- 如何实现：空闲分区以地址递增的次序排列。每次分配内存时顺序查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区

### 最佳适应算法

- 算法思想：由于动态分区分配是一种连续分配方式，为各进程分配的空间必须是连续的一整片区域。因此为了保证当大进程到来时能有连续的大片空间，可以尽可能地留下大片的空闲区，即，优先使用更小的空闲区
- 如何实现：空闲分区按容量递增次序链接。每次分配时顺序查找空闲分区链（或空闲分区表），找到大小能满足要求的第一个空闲分区
- 缺点：每次都选最小的分区进行分配，会留下越来越多的、很小的、难以利用的内存块。因此这种算法会产生很多的外部碎片

### 最坏适应算法

- 又称最大适应算法（Largest Fit）
- 算法思想：为了解决最佳适应算法的问题（即留下太多难以利用的小碎片），可以在每次分配时优先使用最大的连续空闲区，这样分配后剩余的空闲区就不会太小，更方便使用
- 如何实现：空闲分区按容量递减次序链接，每次分配时顺序查找空闲分区链，找到大小满足要求的第一个空闲分区
- 缺点：每次都选最大的分区进行分配，虽然可以让分配后留下的空闲区更大，更可用，但是这种方式会导致较大的连续空间被迅速 用完。如果之后有大进程到达，就没有内存分区可用

### 邻近适应算法

- 算法思想：首次适应算法每次都从链头开始查找的。这可能导致低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些分区，因此也增加了查找的开销。如果每次都从上次查找结束的位置开始检索，就能解决上述问题
- 如何实现：空闲分区以地址递增的顺序排列（可排成循环链表）。每次分配内存都从上次查找结束的位置开始查找空闲分区链，找到大小能满足要求的第一个空闲分区
- 首次适应算法每次都从头查找，每次都要检索低地址的小分区。但是这种规则也决定了当低地址部分有更小的分区可用满足要求时，会更可能用到低地址部分的小分区，也会跟更有可能把高地址部分的大分区保留下来（最佳适应算法的优点）
- 邻近适应算法的规则可能会导致无论低地址、高地址部分的空闲分区都有相同的概率被使用，也就导致了高地址部分的大分区更可能被使用，划分为小分区，最后导致无大分区可用（最大适应算法的缺点）
- 综合来看，首次适应算法的效果反而最好

## （六）基本分页存储管理的概念

### 什么是分页(paging)存储

- 将内存空间分为一个个大小相等的分区（比如：每个分区 4 KB），每个分区就是一个页框（页框=页帧=内存块=物理块=物理页面）。每个页框有一个编号，即页框号（页框号=页帧号=内存块号=物理块号=物理页号），页框号从 0 开始
- 将进程的逻辑地址空间也分为与页框大小相等的一个个部分，每个部分称为一个页或页面。每个页也有一个编号，即页号，页号也是从 0 开始
- 操作系统以页框为单位为各个进程分配内存空间。进程的每个页面分别放入一个页框中。也就是说，进程的页面与内存的页框有一一对应的关系。各个页面不必连续存放，可以放到不相邻的各个页框中

### 重要的数据结构——页表
  - 为了能知道进程的每个页面在内存中存放的位置，操作系统要为每个进程建立一张页表（页表通常存在PCB中）
    - 一个进程对应一张页表
    - 进程的每个页面对应一个页表项
    - 每个页面由页号和块号组成
    - 页表记录进程页面和实际存放的内存块之间的映射关系
    - 每个页表项的长度是相同的
### 问题1：每个页表项占多少字节
- 假设某系统的物理内存为 4GB，页面大小为 4KB，则每个页表项至少应该为多少字节
  - 内存块大小 = 页面大小 = 4KB = 2<sup>12</sup> B
  - 4GB的内存总共被分为 2<sup>32</sup> / 2<sup>12</sup> = 2<sup>20</sup> 个内存块
  - 内存块号的范围应该是 0 ~ 2<sup>20</sup>-1
  - 内存块号至少要用 20bit 来表示
  - 至少要用 3B 来表示块号 （24bit）
  - 而关于页号，页表项是连续存放的，因此页号可以是隐含的，不占存储空间
    - 假设页表中的各页表项从内存地址为X的地方开始连续存放，那么页号为 i 的页表项的存放地址为 X+3*i
  - 由于页号是隐含的，因此每个页表项占 3B，存储整个页表至少需要 3*(n+1)B
  - 注意：页表记录的只是内存块号，而不是内存的起始地址。J号内存块的起始地址 = J*内存块大小
- 重要考点：计算机中内存块的数量 - > 页表项中块号至少占多少字节
### 问题2：如何实现地址的转换
- 将进程地址空间分页之后，操作系统该如何实现逻辑地址到物理地址的转换？
- 特点：虽然进程的每个页面是离散存放的，但是页面内部是连续存放的
- 如果要访问逻辑地址A，则：
  1. 确定逻辑地址A对应的页号P
  2. 找到P号页面在内存中的起始地址（查页表）
  3. 确定逻辑地址A的页内偏移量W
- 逻辑地址A对应的物理地址 = P号页面在内存中的起始地址 + 页内偏移量
- 子问题：如何确定应该逻辑地址对应的页号、页内偏移量？
  - 例：在某计算机系统中，页面大小为50B，某进程逻辑地址空间大小为200B，则逻辑地址110对应的页号、页内偏移量是多少
    - 页号 = 逻辑地址 / 页面长度（取除法的整数部分）
    - 页内偏移量 = 逻辑地址 % 页面长度（取除法的余数部分）
- 如果每个页面大小为 2<sup>k</sup> B，用二进制数表示逻辑地址，则末尾K位即为页内偏移量，其余部分就是页号
  - 逻辑地址的拆分更加迅速
  - 物理地址的计算更加迅速
- 逻辑地址结构：
  - 地址结构包含两个部分：前一部分为页号，后一部分为页内偏移量。
  - 如果有 K 位表示页内偏移量，则说明该系统中一个页面大小为 2<sup>K</sup> 个内存单元
  - 如果有 M 位表示页号，则说明在该系统中，一个进程最多允许有 2<sup>M</sup> 个页面

## （七）基本地址变换机构

- 重点理解、记忆基本地址变换机构（用于实现逻辑地址到物理地址转换的一组硬件机构）的原理和流程
- 基本地址变换机构可以借助进程的页表将逻辑地址转换为物理地址。
- 通常会在系统中设置一个页表寄存器（PTR），存放页表在内存中的起始地址F和页表长度M。进程未执行时，页表的初始地址和页表长度放在进程控制块PCB中，当进程被调度时，操作系统内核会把它们放到页表寄存器中
- 页面大小是2的整数幂，设页面大小为L，逻辑地址到物理地址E的变换过程如下：
  1. 根据逻辑地址计算出页号、页内偏移量
  2. 判断页号是否越界。比较页号 P 和页表长度 M，若 P >= M，则发生越界中断；否则继续执行（注意：页号是从0开始的，而页表长度至少是1，因此 P=M 时也会越界
  3. 查询页表，找到页号对应的页表项，确定页面存放的内存块号（注意区分页表项长度、页表长度、页面大小的区别。页表长度指的是这个页表中总共有几个页表项，即总共有多少页；页表项长度指的是每个页表项占多大的存储空间；页面大小指的是一个页面占多大的存储空间）
  4. 利用内存块号和页内偏移量得到物理地址
  5. 访问目标单元
- 例：若页面大小为 1K 字节，页号 2 对应的内存块号 b=8，将逻辑地址 A=2500 转换为物理地址 E
  - 等价描述：某系统按字节寻址，逻辑地址结构中，页内偏移量占10位，页号2对应的内存块号 b=8，将逻辑地址 A=2500 转换为物理地址 E
  - 解：
    1. 根据逻辑地址计算页号和页内偏移量：
       - 页号：P = 2500 / 1024 = 2
       - 页内偏移量：W = 2500 % 1024 = 452
    2. 根据题目，页号2没有越界，其存放的内存块号为 8
    3. 物理地址 E = 8*1024 + 452 = 8644
- 在分页存储管理中，只要确定了每个页面的大小，逻辑地址结构就确定了。因此，页式管理中地址是一维的。即只要给出一个逻辑地址，系统就可以自动算出页号、页内偏移量两个部分，并不需要显式告诉系统这个逻辑地址中，页内偏移量占多少位
- 对页表项大小的进一步探讨
  - 假设某系统物理内存大小为 4GB，页面大小为 4KB，内存总共会被分成 2<sup>32</sup> / 2<sup>12</sup> = 2<sup>20</sup> 个内存块，因此内存块号的范围应该是 0~2<sup>20</sup>-1。因此至少要 20 个二进制位才能表示这么多内存块号，因此至少要 3 个字节才够
    - 各页表项会按顺序连续地存放在内存中，如果页表在内存中存放的起始地址为X，则 M 号页对应的页表项是存放在内存地址为 `X + 3*M`。一个页面大小为 4KB，则每个页框可以存放 4096%3 = 1365 个页表项，但是这个页框会剩余 4096%3=1B 个业内碎片。因此，1365号页表项存放的地址为 `X+3*1365+1`。如果每个页表项占 4 字节，则每个页框刚好可以存放 1024 个页表项。1024号页表项虽然是存放在下一个页框内的，但是它的地址依然可以用 `X + 4*1024`得出
  - 结论：理论上，页表项长度为 3B 即可表示内存块号的范围，但是，为了方便页表的查询，常常会让一个页表项占更多的字节，使得每个页面恰好可以装得下整数个页表项

## （八）具有快表的地址变换机构

- 具有快表的地址变换机构，是基本地址变换的改进版本
- 总览：
  - 什么是快表
  - 引入快表后，地址变换的过程
  - 局部性原理

### 什么是快表

- 快表，又称联想寄存器（TLB，translation lookaside buffer)，是一种访问速度比内存快很多的高速缓存（cache）（TLB不是内存），用来存放最近访问的页表项的副本，可以加速地址变换的速度。与此对应，内存中的页表常称为满表
- 引入快表后，地址的变换过程：
  1. CPU给出逻辑地址，由某个硬件算得页号、页内偏移量，将页号与快表中的所有页号进行比较
  2. 如果找到匹配的页号，说明要访问的页表项在快表中有副本，则直接从中取出与该页对应的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后，访问该物理地址对应的内存单元。因此，若快表命中，则访问的某个逻辑地址仅需一次访存即可
  3. 如果没有找到匹配的页号，则需要访问内存中的页表，找到对应页表项，得到页面存放的内存块号，再将内存块号与页内偏移量拼接形成物理地址，最后，访问该物理地址对应的内存单元。因此，若快表未命中，则访问某个逻辑地址需要两次访存（注意：在找到页表项后，应同时将其存入快表，以便后面可能的再次访问。但若快表已满，则必须按照一定的算法对旧的页表项进行替换）
- 由于查询快表的速度比查询页表的速度快得多，因此只要快表命中，就可以节约很多时间。因为局部性原理，一般来说快表的命中率可以达到90%以上
- 例：某系统使用基本分页存储管理，并采用了具有快表的地址变换机构。访问一次快表耗时1us，访问一次内存耗时100us。若快表的命中率为90%，那么访问一个逻辑地址的平均耗时是多少？
  - 快表和慢表不同时查找：`（1+100）*0.9+（1+100+100）*0.1=111us`
  - 有的系统支持快表和慢表同时查找：`（1+100）*0.9+（100+100）*0.1=110.9`
- 局部性原理：
  - 时间局部性：如果执行了程序中的某条指令，那么不久后这条指令很有可能再次执行；如果某个数据被访问过，不久之后该数据很可能再次被访问（因为程序中存在大量循环）
  - 空间局部性：一旦程序访问了某个单元，在不久之后，其附近的存储单元也很有可能被访问（因为很多数据在内存中都是连续存放的）

## （九）两级页表

- 总览：
  - 单级页表存在什么问题？如何解决？
  - 两级页表的原理、逻辑地址结构
  - 如何实现地址变换？
  - 两级页表存在的几个细节
- 单级页表存在的问题：
  - 某计算机系统按字节寻址，支持 32 位的逻辑地址，采用分页存储管理，页面大小为 4KB，页表项长度为 4B。4KB = 2<sup>12</sup>B，因此页内地址要用 12 位表示，剩余 20 位表示页号。因此，该系统中用户进程最多有 2<sup>20</sup> 页。相应的，一个进程的页表中，最多会有 2<sup>20</sup> = 1M= 1048576 个页表项，所以一个页表最大需要 2<sup>20</sup>`*`4B=2<sup>22</sup>B，共需要 2<sup>22</sup> / 2<sup>12 </sup>= 2<sup>10</sup>个页框存储该页表。根据页号查询页表的方法：K 号页对应的页表项存放位置 = 页表初始地址 + K`*`4。要在所以的页表项都连续存放的基础上才能用到这种方法找到页表项。根据局部性原理可知，很多时候，进程在一段时间内只需要访问某几个页面就可以正常运行了。因此没有必要让整个页表都常驻运行
- 如何解决单级页表的问题
  - 问题一：页表必须连续存放，因此当页表很大时，需要占用很多个连续的页框
    - 思考：我们是如何解决进程在内存中必须连续存储的问题的？
      - 将进程地址空间分页，并为其建立一张页表，记录各页面的存放位置。同样的思路也可用于解决页表必须连续存放的问题，把必须连续存放的页表再分页
    - 可将长长的页表进行分组，使每个内存块刚好可以进入一个分组（比如上个例子中，页面大小4KB，每个页表项4B，每个页面可存放1K个页表项，因此每1K个连续的页表项为一组，每组刚好占一个内存块，再讲各组离散地分散到各个内存块中）
    - 另外，要为离散分配的页表再建立一张页表，称为页目录表，或称外层页表，或称顶层页表
    - 两级页表的原理、逻辑地址结构
      - 一级页号、二级页号、页内偏移量
    - 如何实现地址变换？
      - 例：将逻辑地址（0000000000，0000000001，111111111111）转换为物理地址，用十进制表示
        1. 按照地址结构将逻辑地址分为三部分
        2. 从PCB中读出页目录表始址，再根据一级页号查页目录表，找到下一级页表在内存中的存放位置
        3. 根据二级页号查表，找到最终想访问的内存块号
        4. 结合页内偏移量得到物理地址
  - 问题二：没有必要让整个页表常驻内存，因为进程在一段时间内可能只需要访问几个特点的页面
    - 可以在需要访问页面时才把页面调入内存（虚拟存储技术）。可以在页表项中增加一个标志位，用于表示该页面是否已经调入内存
    - 若想访问的页面不在内存中，则产生缺页中断（内中断），如何将目标页面从外存调入内存
- 需要注意的几个细节
  1. 若采用多级页表机制，则各级页表的大小不能超过一个页面
     - 例：某系统按字节编址，采用40位逻辑地址，页面大小为4KB，页表项大小为4B，假设采用纯页式存储，则要采用（）级页表，页内偏移量为（）位？
       - 页面大小 = 4KB = 2<sup>12</sup>B，按字节编址，因此页内偏移量为12位
       - 页号 = 40-12 = 28位
       - 页面大小 = 2<sup>12</sup>B，页表项大小 = 4B，则每个页面可存放 2<sup>12</sup> / 4 = 2<sup>10 </sup>个页表项
       - 因此各级页表最多包含 2<sup>10</sup> 个页表项，需要 10 位二进制位才能映射到 2<sup>10</sup>，因此每一级的页表对应页号应为 10 位。总共 28 位的页号至少要分为三级
       - 逻辑地址：页号 28 位、页内偏移量 12 位
       - 逻辑地址：一级页号 8 位、二级页号 10 位、三级页号10位、页内偏移量12位
  2. 两级页表的访存次数分析（假设没有快表机构）
     - 第一次访存：访问内存中的页目录表
     - 第二次访存：访问内存中的二级页表
     - 第三次访存：访问目标内存单元

## （十）基本分段存储管理

- 基本分段存储管理，与分页最大的区别就是，离散分配时所分配地址空间的基本单位不同
- 总览：
  - 什么是分段
  - 什么是段表
  - 如何实现地址变换
  - 分段、分页管理的对比

### 分段

- 进程的地址空间：按照程序自身的逻辑关系划分为若干个段，每个段都有一个段名（在低级语言中，程序员使用段名来编程），每段从0开始编址
- 内存分配规则：以段为单位进行分配，每个段在内存中占据连续空间，但各段之间可以不相邻
- 分段系统的逻辑地址结构由段号（段名）和段内地址（段内偏移量）所组成
  - 段号的位数决定了每个进程最多可以分为几个段
  - 段内地址位数决定了每个段的最大长度是多少

### 段表

- 程序分为多个段，各段离散地装入内存，为了保证程序能正常运行，就必须能从物理内存中找到各个逻辑段的存放位置。为此，需为每个进程建立一张段映射表，简称段表
  - 段号、段长、基址
  - 每个段对应一个段表项，其中记录了该段在内存中的起始位置（又称基址）和段的长度
  - 每个段表项的长度是相同的。例如：某系统按字节编址，采用分段存储管理，逻辑地址结构为（段号16位，段内地址16位），因此用16位即可表示最大段长。物理内存大小为4GB（可用32位表示整个物理内存地址空间）。因此，可让每个段表项占16+32=48位，即6B。由于段表项长度相同，因此段号是可用隐含的，不占存储空间。若段表项存放的起始地址为M，则K号段对应的段表项存放的地址为M+K*6
### 如何实现地址变换：
    1. 根据逻辑地址得到段号、段内地址
    2. 判断段号是否越界。若S>=M，则产生越界中断，否则继续执行
    3. 查询段表，找到对应的段表项，段表项的存放地址为F+S*段表项长度
    4. 检查段内地址是否超过段长。若W>=C，则产生越界中断，否则继续执行
    5. 计算得到物理地址
    6. 访问目标内存单元

### 分段、分页管理对比

- 目的
  - 页是信息的物理单位。分页的主要目的是为了实现离散分配，提高内存利用率。分页仅仅是系统管理上的需要，完全是系统行为，对用户是不可见的
  - 段是信息的逻辑单位。分段的主要目的是更好地满足用户需求。一个段通常包含着一组属于一个逻辑模块的信息。分段对用户是可见的，用户编程时需要显式地给出段名
- 大小
  - 页的大小是固定的且由系统给出
  - 段的长度不固定，决定于用户编写的程序
- 维度
  - 分页的用户进程地址空间是一维的，程序员只需要给出一个记忆符即可表示一个地址
  - 分段的用户进程地址空间是二维的，程序员在标识一个地址时既要给出段名，也要给出段内地址
- 分段比分页更容易实现信息的共享和保护
  - 注：不能被修改的代码称为纯代码或可重入代码（不属于临界资源），这样的代码是可共享的。可修改的代码是不能被共享的（比如，有一个代码段中有很多变量，各进程并发地同时访问可能造成数据不一致
- 访存次数
  - 分页（单级页表）：第一次访存，查询内存中的页表；第二次访存，查询目标内存单元。总共两次访存。总共两次
  - 分段：第一次访存，查询内存中的段表；第二次访存，查询目标内存单元。总共两次访存。总共两次
    - 与分页系统类似，分段系统中也可引入快表机构，将近期访问过的段表项放到快表中，这样可以少因此访问，加快地址变换速度

## （十一）段页式管理方式

- 总览：
  - 分页、分段管理方式中最大的优缺点
  - 分段+分页的结合：段页式管理方式
  - 段表、页表
  - 如何实现地址变换

### 分页、分段的优缺点

- 分页管理：
  - 优点：内存空间利用率高，不会产生外部碎片，只会有少量的页内碎片
  - 缺点：不方便按照逻辑模块实现信息的共享和保护
- 分段管理：
  - 很方便按照逻辑模块实现信息的共享和保护
  - 如果段长过大，为其分配很大的连续空间会很不方便。另外，段式管理会产生外部碎片。
    - 注意：分段管理中产生的外部碎片也可以用紧凑来解决，只是需要付出较大的时间代价

### 分段+分页的结合：段页式管理方式

- 将进程按逻辑模块分段，再按各段分页，再将内存空间分为大小相同的内存块/页框/页帧/物理块，进程前将各页面分别装入各内存块中
- 段页式管理的逻辑地址结构：
  - 段号、页号、页内地址（页内偏移量）
  - 段号位数决定了每个进程最大可以分几个段
  - 页号位数决定了每个段最大有多少页
  - 页内偏移量决定了页面大小、内存块大小是多少
- 分段对用户是可见的，程序员编程时需要显式给出段号、段内地址。而将各段分页对用户是不可见的。系统会根据段内地址自动划分页号和页内偏移量。因此段页式管理的地址结构是二维的

### 段表、页表

- 每个段对应一个段表，每个段表项由段号、页表长度、页表存放块号（页表起始地址）组成。每个段表项长度相等，段号是隐含的
  - 根据块号可以算出页表存放的内存地址
- 每个页面对应一个页表项，每个页表项由页号、页面存放的内存块号组成。每个页表项长度相等，页号是隐含的

### 如何实现地址变换

1. 根据逻辑地址得到段号、页号、页内偏移量
2. 判断段号是否越界。若S>=M，则产生越界中断，否则继续执行
3. 查询段表，找到对应的段表项，段表项的存放地址为F+S*段表项长度（第一次访存）
4. 检查页号是否越界，若页号>=页表长度，则发生越界中断，否则继续执行
5. 根据页表存放块号、页号查询页表，找到对应页表项（第二次访存）
6. 根据内存块号、页内偏移量得到最终的物理地址
7. 访问目标内存单元（第三次访存）

- 注意：也可引入快表机构，用段号和页号作为查询快表的关键字。若快表名字则仅需一次访存

## （十二）虚拟内存的基本概念

- 总览：
  - 传统存储管理方式的特征、缺点
  - 局部性原理
    - 时间局部性
    - 空间局部性
    - 高速缓存技术
  - 虚拟内存的定义和特征
  - 如何实现虚拟内存技术

### 传统存储管理方式的特征、缺点

- 传统存储管理方式的特征：
  - 一次性：作业必须一次性全部装入内存后才能开始运行。这会造成两个问题：
    1. 作业很大时，不能全部装入内存，导致大作业无法运行
    2. 当大量作业要求运行时，由于内存无法容纳所有作业，因此只有少量作业能运行，导致多道程序并发度下降
  - 驻留性：一旦作业被装入内存，就会一直驻留在内存中，直至作业运行结束。事实上，在一个时间段内，只需要访问作业的一小部分数据即可正常运行，这就导致了内存中会驻留大量的、暂时用不到的数据，浪费了宝贵的内存资源

### 局部性原理

- 时间局部性：如果执行了程序中的某条指令，那么不久后这条指令很有可能再次执行；如果某个数据被访问过，不久之后该数据很可能再次被访问（因为程序中存在大量循环）
- 空间局部性：一旦程序访问了某个单元，在不久之后，其附近的存储单元也很有可能被访问（因为很多数据在内存中都是连续存放的）

### 虚拟内存的定义和特征

- 基于局部性原理，在程序装入时，可以将程序中很快就会用到的部分装入内存，暂时用不到的部分留在外存，就可以让程序开始执行
- 在程序执行过程中，当访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存，然后继续执行程序
- 若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出到外存
- 在操作系统的管理下，在用户看来似乎有一个比实际内存大得多的内存，这就是虚拟内存
- 虚拟内存有以下三个主要特征：
  - 多次性：无需在作业运行时一次性全部装入内存，而是允许被分成多次调入内存
  - 对换性：在作业运行时无需一直常驻内存，而是允许在作业运行过程中，将作业换入、换出
  - 虚拟性：从逻辑上扩充了内存的容量，使用户看到的内存容量，远大于实际的容量

### 如何实现虚拟内存技术

- 虚拟内存技术，允许一个作业分多次调入内存。如果采用连续分配空间，会不方便实现。因此虚拟内存的实现需要建立在离散分配的内存管理方式基础上
- 虚拟内存的实现：
  - 请求分页存储管理
  - 请求分段存储管理
  - 请求段页式存储管理
- 虚拟内存技术和传统非连续分配存储管理的主要区别：
  - 在程序执行过程中，当所访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存，然后继续执行程序（请求调页功能）
  - 若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出外存（页面置换功能）

## （十三）请求分页存储管理

- 请求分页存储管理与基本分页存储管理主要区别：
  - 在程序执行过程中，当所访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存，然后继续执行程序（请求调页功能）
  - 若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出外存（页面置换功能）
- 请求分页管理方式：
  - 页表机制
  - 缺页中断机构
  - 地址变换机构

### 页表机制

- 与基本分页管理相比，请求分页管理中，为了实现请求调页，操作系统需要知道每个页面是否已经调入内存；如果还没调入，那么也需要知道该页面在外存中存放的位置
- 当内存空间不够时，要实现页面置换，操作系统需要通过某些指标来决定到底换出哪个页面；有的页面没有被修改过，就不用再浪费时间写回外存。有的页面修改过，就需要将外存中的旧数据覆盖，因此，操作系统也需要记录各个页面是否被修改过的信息
- 请求页表项新增了四个字段：
  - 状态位：是否调入内存
  - 访问字段：可记录最近被访问过几次，或记录上次访问的时间，供置换算法选择换出页面时参考
  - 修改位：页面调入内存后是否被修改过
  - 外存地址：页面在外存中存放的位置

### 缺页中断机构

- 在请求分页系统中，每当要访问的页面不在内存中时，便产生一个缺页中断，然后由操作系统的缺页中断处理程序处理中断
- 此时缺页的进程阻塞，放入阻塞队列，调页完成后再将其唤醒，放回就绪队列
- 如果内存中有空闲块，则为进程分配一个空闲块，将所缺页面装入该块，并修改页表中相应的页表项
- 如果内存中没有内存块，则由页面置换算法选择一个页面淘汰，若该页面在内存期间被修改过，则要将其写回外存。未修改过的页面不用写回外存
- 缺页中断是因为当前执行的指令想要访问的目标页面未调入内存而产生的，因此属于内中断
- 一条指令在执行期间，可能产生多次缺页中断。（如：copy A to B，将逻辑地址A中的数据复制到逻辑地址B，而A、B属于不同的页面且均未调入内存，则有可能产生两次中断）

### 地址变换机构

- 请求分页存储管理与基本分页存储管理主要区别：
  - 在程序执行过程中，当所访问的信息不在内存时，由操作系统负责将所需信息从外存调入内存，然后继续执行程序（请求调页功能）
  - 若内存空间不够，由操作系统负责将内存中暂时用不到的信息换出外存（页面置换功能）
- 新增步骤：
  1. 请求调页（查到页表时进行判断
  2. 页面置换（需要调入页面，但没有空闲内存块时进行）
  3. 需要修改请求页表中新增的表项
- 注意：
  - 快表中有的页面一定是在内存中的。若某个页面被换出外存，则快表中的相应表项也要删除，否则可能访问错误的页面
- 补充算法：
  - 只有写指令才需要修改修改位。并且，一般来说只需修改快表中的数据，只有要将快表项删除时才需要写回内存中的慢表。这样可以减少访存次数
  - 和普通的中断处理一样，缺页中断处理依然需要保留CPU现场
  - 需要用某种页面置换算法来决定一个换出页面
  - 换入换出页面都需要启动慢速的IO操作，可见，如果换入换出太频繁，会有很大的开销
  - 页面调入内存后，需要修改慢表，同时也需要将表项复制到快表中

## （十四）页面置换算法

- 页面置换算法：页面的换入、换出需要磁盘IO，会有较大的开销，因此好的页面置换算法应该追求更少的缺页率
  - 最佳置换算法（OPT）
  - 先进先出置换算法（FIFO）
  - 最近最久未使用置换算法（LRU）
  - 时钟置换算法（CLOCK）
  - 改进型的时钟置换算法

### 最佳置换算法（OPT）

- 最佳置换算法（OPT，Optimal）：每次选择淘汰的页面将是以后永不使用，或者在最长时间内不再被访问的页面，这样可以保证最低的缺页率

- 例：假设系统为某进程分配了三个内存块，并考虑到有以下页面号引用串（会依次访问这些页面）：7、0、1、2、0、3、0、4、2、3、0、3、2、1、2、0、1、7、0、1

  - | 访问页面 | 7    | 0    | 1    | 2    | 0    |
    | -------- | ---- | ---- | ---- | ---- | ---- |
    | 内存块1  | 7    | 7    | 7    | 2    |      |
    | 内存块2  |      | 0    | 0    | 0    |      |
    | 内存块3  |      |      | 1    | 1    |      |
    | 是否缺页 | √    | √    | √    | √    |      |

  - | 3    | 0    | 4    | 2    | 3    | 0    |
    | ---- | ---- | ---- | ---- | ---- | ---- |
    | 2    |      | 2    |      |      | 2    |
    | 0    |      | 4    |      |      | 0    |
    | 3    |      | 3    |      |      | 3    |
    | √    |      | √    |      |      | √    |

  - | 3    | 2    | 1    | 2    | 0    | 1    |
    | ---- | ---- | ---- | ---- | ---- | ---- |
    |      |      | 2    |      |      |      |
    |      |      | 0    |      |      |      |
    |      |      | 1    |      |      |      |
    |      |      | √    |      |      |      |

  - | 7    | 0    | 1    |      |      |      |
    | ---- | ---- | ---- | ---- | ---- | ---- |
    | 7    |      |      |      |      |      |
    | 0    |      |      |      |      |      |
    | 1    |      |      |      |      |      |
    | √    |      |      |      |      |      |

  - 第一个2出现时：选择从0、1、7中淘汰一页。按最佳置换的规则，往后寻找，最后应该出现的页号就是要淘汰的页面。7最后出现，淘汰7

  - 第一个3出现时：选择从0、1、2中淘汰一页。按最佳置换的规则，往后寻找，最后应该出现的页号就是要淘汰的页面。1最后出现，淘汰

  - ...以此类推

  - 整个过程中缺页中断发生了9次，页面置换发生了6次

    - 注意：缺页时未必发生页面置换。若还有可用的空闲内存块，就不用进行页面置换

  - 缺页率 = 9 / 20 = 45%

- 最佳置换算法可以保证最低的缺页率，但实际上，只有在进程执行的过程中才能知道接下来会访问到的是哪个页面。操作系统无法提前预判页面访问序列。因此，最佳置换算法是无法实现的

### 先进先出置换算法（FIFO）

- 先进先出置换算法（FIFO）：每次选择淘汰的页面是最早进入内存的页面

- 实现方法：把调入内存的页面根据调入的先后顺序排成一个队列，需要换出页面时选择队头页面即可。队列的最大长度取决于系统为进程分配了多少个内存块

- 例：假设系统为进程分配了3个内存块，并考虑到有以下页面好引用串：3、2、1、0、3、2、4、3、2、1、0、4

  - | 访问页面 | 3    | 2    | 1    | 0    | 3    |
    | -------- | ---- | ---- | ---- | ---- | ---- |
    | 内存块1  | 3    | 3    | 3    | 0    | 0    |
    | 内存块2  |      | 2    | 2    | 2    | 3    |
    | 内存块3  |      |      | 1    | 1    | 1    |
    | 是否缺页 | √    | √    | √    | √    | √    |

  - | 2    | 4    | 3    | 2    | 1    | 0    |
    | ---- | ---- | ---- | ---- | ---- | ---- |
    | 0    | 4    |      |      | 4    | 4    |
    | 3    | 3    |      |      | 1    | 1    |
    | 2    | 2    |      |      | 2    | 0    |
    | √    | √    |      |      | √    | √    |

  - | 4    |
    | ---- |
    | 4    |
    | 1    |
    | 0    |
    | √    |

  - 

  - 分配3个内存块时，缺页次数：9次

- 例：假设系统为进程分配了4个内存块，并考虑到有以下页面好引用串：3、2、1、0、3、2、4、3、2、1、0、4

  - | 访问页面 | 3    | 2    | 1    | 0    | 3    |
    | -------- | ---- | ---- | ---- | ---- | ---- |
    | 内存块1  | 3    | 3    | 3    | 3    |      |
    | 内存块2  |      | 2    | 2    | 2    |      |
    | 内存块3  |      |      | 1    | 1    |      |
    | 内存块4  |      |      |      | 0    |      |
    | 是否缺页 | √    | √    | √    | √    |      |

  - | 2    | 4    | 3    | 2    | 1    | 0    |
    | ---- | ---- | ---- | ---- | ---- | ---- |
    |      | 4    | 4    | 4    | 4    | 0    |
    |      | 2    | 3    | 3    | 3    | 3    |
    |      | 1    | 1    | 2    | 2    | 2    |
    |      | 0    | 0    | 0    | 1    | 1    |
    |      | √    | √    | √    | √    | √    |

  - 

  - | 4    |      |      |      |      |      |
    | ---- | ---- | ---- | ---- | ---- | ---- |
    | 0    |      |      |      |      |      |
    | 4    |      |      |      |      |      |
    | 2    |      |      |      |      |      |
    | 1    |      |      |      |      |      |
    | √    |      |      |      |      |      |

  - 分配4个内存块时，缺页次数：10次

- Belady异常：当为进程分配的物理块数增大时，缺页次数不减反增的异常现象

- 只有FIFO算法会产生Belady异常。另外，FIFO算法虽然实现简单，都是该算法与进程实际运行时的规律不适应，因为先进入的页面也有可能最经常被访问。因此，算法性能差

### 最近最久未使用置换算法（LRU）

- 最近最久未使用置换算法（LRU，least recently used）：每次淘汰的页面是最近最久未使用的页面

- 实现方法：赋予每个页面对应的页表项中，用访问字段记录该页面自上次被访问以来所经历的时间t。当需要淘汰一个页面时，选择现有页面中t值最大的，即最近最久未使用的页面

- 例：假设系统为进程分配了4个内存块，并考虑到有以下页面好引用串：1、8、1、7、8、2、7、2、1、8、3、8、2、1、3、1、7、1、3、7

  - | 访问页面 | 1    | 8    | 1    | 7    | 8    |
    | -------- | ---- | ---- | ---- | ---- | ---- |
    | 内存块1  | 1    | 1    |      | 1    |      |
    | 内存块2  |      | 8    |      | 8    |      |
    | 内存块3  |      |      |      | 7    |      |
    | 内存块4  |      |      |      |      |      |
    | 是否缺页 | √    | √    |      | √    |      |

  - | 2    | 7    | 2    | 1    | 8    | 3    |
    | ---- | ---- | ---- | ---- | ---- | ---- |
    | 1    |      |      |      |      | 1    |
    | 8    |      |      |      |      | 8    |
    | 7    |      |      |      |      | 3    |
    | 2    |      |      |      |      | 2    |
    | √    |      |      |      |      | √    |

  - | 8    | 2    | 1    | 3    | 1    | 7    |
    | ---- | ---- | ---- | ---- | ---- | ---- |
    |      |      |      |      |      | 1    |
    |      |      |      |      |      | 7    |
    |      |      |      |      |      | 3    |
    |      |      |      |      |      | 2    |
    |      |      |      |      |      | √    |

  - | 1    | 3    | 7    |      |      |      |
    | ---- | ---- | ---- | ---- | ---- | ---- |
    |      |      |      |      |      |      |
    |      |      |      |      |      |      |
    |      |      |      |      |      |      |
    |      |      |      |      |      |      |
    |      |      |      |      |      |      |

  - 在手动做题时，若需要淘汰页面，可以逆向检查此时在内存中的几个页面号。在逆向扫描过程最后一个出现的页号就是要淘汰的页面

- 该算法的实现需要专门的硬件支持，虽然算法性能好，但是实现困难，开销大

### 时钟置换算法（CLOCK）

- 最佳置换算法性能最好，但无法实现；先进先出置换算法实现简单，但算法性能差；最近最久未使用算法性能好，是最接近OPT算法性能的，但是实现起来需要专门的硬件支持，算法开销大
- 时钟置换算法是一种性能和开销较均衡的算法，又称CLOCK算法，或最近未用算法（NRU，Not Recently Used）
- 简单的CLOCK算法实现方法：为每个页面设置一个访问位，再将内存中的页面都通过链接指针链接成一个循环队列。当某页被访问时，其访问位置为1。当需要淘汰一个页面时，只需检查页的访问位。如果是0，就选择该页换出；如果是1，则将它置为0，暂不换出，继续检查下一个页面，若第一轮扫描中所有页面都是1，则将这些页面的访问位依次置为0后，再进行第二轮扫描（第二轮扫描中一定会有访问位为0的页面，因此简单的CLOCK算法选择一个淘汰页面最大会经过两次扫描）
  - 例：假设系统为进程分配了5个内存块，并考虑到有以下页面好引用串：1、3、4、2、5、6、3、4、7
    - 1、3、4、2、5
    - 6进入时需要淘汰一个页面。第一轮依次将5个页面的访问位由1置为0，第二轮淘汰1
    - 3、4、2、5、1
    - 3、4依次访问，将其访问位置为1
    - 2、5、1、3、4
    - 7进入时需要淘汰一个页面。2的标志位为0，淘汰
- 改进型的时钟置换算法：
  - 算法思想：
    - 简单的时钟置换算法仅考虑到一个页面最近是否被访问过。事实上，如果被淘汰的页面没有被修改过，就不需要执行IO操作写回外存。只有被淘汰的页面被修改过时，才需要写回外存。因此，除了考虑一个页面最近有没有被访问过之外，操作系统还应考虑页面有没有被修改过。在其他条件都相同时，应优先淘汰没有修改过的页面，避免IO操作。这就是改进型的时钟置换算法的思想。修改位=0，表示页面没有被修改过；修改位=1，表示页面被修改过。为方便讨论，用（访问位，修改位）的形式表示各页面状态。如（1，1）表示一个页面近期被访问过。且被修改过。
  - 算法规则：
    - 将所有可能被置换的页面排成一个循环队列
    - 第一轮：从当前位置开始扫描到第一个（0，0）的帧用于替换。本轮扫描不修改任何标志位
      - 第一优先级：最近未访问且没修改
    - 第二轮：若第一轮扫描失败，则重新扫描，查找第一个（0，1）的帧用于替换。本轮将所有扫描过的帧访问位设为0
      - 第二优先级：最近未访问但修改过
    - 第三轮：若第二轮扫描失败，则重新扫描，查找第一个（0，0）的帧用于替换。本轮扫描不修改任何标志位
      - 第三优先级：最近访问过但未修改过
    - 第四轮：若第三轮扫描失败，则重新扫描，查找第一个（0，1）的帧用于替换
      - 第四优先级：最近访问过且修改过
    - 由于第二轮已将所有帧的访问位设为0，因此经过第三轮、第四轮扫描一定会有一个帧被选中，因此改进型CLOCK置换算法最多会进行四轮扫描

## （十五）页面分配策略、抖动、工作集

- 页面分配策略、抖动、工作集
  - 驻留集
  - 页面分配、置换策略
    - 固定分配局部替换
    - 可变分配全局替换
    - 可变分配局部替换
  - 调入页面的时机
  - 从何处调页
  - 抖动（颠簸）现象
  - 工作集

### 驻留集

- 驻留集：指请求分页存储管理中给进程分配的物理块的集合。
- 在采用了虚拟存储技术的系统中，驻留集大小一般小于进程的总大小。
- 若驻留集太小，会导致缺页频繁，系统要花大量的时间来处理缺页，实际用于进程推进的时间很少；若驻留集太大，又会导致多道程序并发度下降，资源利用率降低。所以应该选择一个合适的驻留集大小
- 固定分配：操作系统为每个进程分配一定数目的物理块，在进程运行期间不再改变。即，驻留集大小不变
- 可变分配：先为每个进程分配一定数目的物理块，在进程运行期间，可根据情况做适当的增加或减少。即，驻留集大小可变
- 局部替换：发生缺页时只能选进程自己的物理块进行置换
- 全局置换：可以将操作系统保留的空闲物理块分配给缺页进程，也可以将别的进程持有的物理块置换到外存，再分配给缺页进程
  - 区别在于：局部置换只能拿自己的；全局置换还可以拿空闲的和别人的

### 页面分配、置换策略

- 固定分配局部替换:
  - 系统为每个进程分配一定数量的物理块，在整个运行期间都不改变。若进程在运行中发生缺页， 则只能从该进程在内存中的页面中选出一页换出， 然后再调入需要的页面。
  - 这种策略的缺点是：很难在刚开始就确定应为每个进程分配多少个物理块才算合理。(采用这种策略的系统可以根据进程大小、优先级、或是根据程序员给出的参数来确定为一个进程分配的内存块数)
- 可变分配全局替换：
  - 刚开始会为每个进程分配一定数量的物理块。操作系统会保持一个空闲物理块队列。当某进程发生缺页时，从空闲物理块中取出一块分配给该进程:若已无空闲物理块，则可选择一个未锁定的页面换出外存，再将该物理块分配给缺页的进程。
  - 采用这种策略时，只要某进程发生缺页，都将获得新的物理块，仅当空闲物理块用完时，系统才选择一个未锁定的页面调出。被选择调出的页可能是系统中任何一个进程中的页，因此这个被选中的进程拥有的物理块会减少，缺页率会增加。
  - 系统会锁定一些页面，这些页面中的内容不能置换出外存（如：重要的内核数据可以设定为锁定）
- 可变分配局部替换:刚开始会为每个进程分配一定数量的物理块。当某进程发生缺页时，只允许从该进程自己的物理块中选出一个进行换出外存。如果进程在运行中频繁地缺页，系统会为该进程多分配几个物理块，直至该进程缺页率趋势适当程度;反之，如果进程在运行中缺页率特别低，则可适当减少分配给该进程的物理块。
- 区别：
  - 可变分配全局置换：只要缺页就给分配新物理块
  - 可变分配局部置换：要根据发生缺页的频率来动态地增加或减少进程的物理块

### 调入页面时机

- 预调页策略：根据局部性原理，一次调入若干个相邻的页面可能比一次调入一个页面更高效。但如果提前调入的页面中大多数都没被访问过，则又是低效的。因此可以预测不久之后可能访问到的页面，将它们预先调入内存，但目前预测成功率只有50%左右。故这种策略主要用于进程的首次调入，由程序员指出应该先调入哪些部分。
  - 运行前调入
  - 主要指空间局部性，即：如果当前访问了某个内存单元，在之后很有可能会接着访问与其相邻的那些内存单元
- 请求调页策略：进程在运行期间发现缺页时才将所缺页面调入内存。由这种策略调入的页面一定会被访问到，但由于每次只能调入一页，而每次调页都要磁盘I/O操作，因此I/O开销较大。
  - 运行时调入

### 从何处调页

- 系统拥有足够的对换区空间：
  - 页面的调入、调出都是在内存与对换区之间进行，这样可以保证页面的调入、调出速度很快。在进程运行前，需将进程相关的数据从文件区复制到对换区。
- 系统缺少足够的对换区空间：
  - 凡是不会被修改的数据都直接从文件区调入，由于这些页面不会被修改，因此换出时不必写回磁盘，下次需要时再从文件区调入即可。对于可能被修改的部分，换出时需写回磁盘对换区，下次需要时再从对换区调入。
- Unix方式：
  - 运行之前进程有关的数据全部放在文件区，故未使用过的页面，都可从文件区调入。若被使用过的页面需要换出，则写回对换区，下次需要时从对换区调入。

### 抖动（颠簸）现象

- 抖动：刚刚换出的页面马上又要换出外存，这种频繁的页面调度行为称为抖动，或颠簸。
- 产生抖动的主要原因是进程频繁访问的页面数目高于可用的物理块数（分配给进程的物理块不够）
  - 为进程分配的物理块太少，会使进程发送抖动现象。为进程分配的物理块太多，又会降低系统整体的并发度，降低某些资源的利用率
  - 为了研究应该为每个进程分配多少个物理块，Denning提出了进程工作集概念
### 工作集
- 工作集：指在某段时间间隔内，进程实际访问页面的集合
  - 操作系统会根据窗口尺寸来算出工作集
  - 例：某进程的页面访问序列如下，窗口尺寸为4，各时刻的工作集为？
  - 24、15、18、23、24、17、18、24、18、17、17、15
    - 24、15、18、23。这部分窗口的工作集为：24、15、18、23
    - 18、24、18、17。这部分窗口的工作集为：18、24、17
  - 工作集大小可能小于窗口尺寸，实际应用中，操作系统可以统计进程的工作集大小，根据工作集大小给进程分配若干内存块。如：窗口尺寸为5，经过一段时间的监测发现某进程的工作集最大为3，那么说明该进程有很好的局部性，可以给这个进程分配3个以上的内存块即可满足进程的运行需要
- 一般来说，驻留集大小不能小于工作集大小，否则进程运行过程中将频繁缺页
- 拓展：基于局部性原理可知，进程在一段时间内访问的页面与不久之后会访问的页面是有相关性的。因此，可以根据进程近期访问的页面集合（工作集）来设计一种页面置换算法（选择一个不在工作集中的页面进行淘汰）

## （十六）内存映射文件

- 内存映射文件
  - 内存映射文件是什么？有什么用？
  - 传统的文件访问方式
  - 内存映射文件的原理和作用

### 内存映射文件（Memory-Mapped Files）

- 内存映射文件：操作系统向上层程序员提供的功能（系统调用）
- 作用：
  - 方便程序员访问文件数据
  - 方便多个进程共享同一个文件

### 传统的文件访问方式

- open系统调用：打开文件
- seek系统调用：将读写指针移到某个位置
- read系统调用：从读写指针所指的位置读入若干数据
- write系统调用：将内存中的指定数据，写回磁盘（根据读写指针确定要写回什么位置）

### 内存映射文件的原理和作用

- 内存映射文件的访问方式：
  - open系统调用：打开文件
  - mmap系统调用：将文件映射到进程的虚拟地址空间
    - 以访问内存的方式访问文件数据
    - 文件数据的读入、写出由操作系统自动完成
    - 进程关闭文件时，操作系统自动将文件被修改的数据写回磁盘
- 多个进程可以映射同一个文件，实现共享。在物理内存中，一个文件对应同一份数据，当一个进程修改文件数据时，另一个进程立马可以看到

# 五.文件管理

## （一）初始文件管理

- 问题：
  - 计算机中存放了各种各样的文件，一个文件有哪些属性？
  - 文件内部的数据应该怎样组织起来？
  - 文件之间又应该怎么组织起来？
  - 从下往上看，OS应该提供哪些功能，才能方便用户、应用程序使用文件？
  - 从上往下看，文件数据应该怎么存放在外存（磁盘）上？
### 文件的属性：
  - 文件名：由创建文件的用户决定文件名，主要是方便用户找到文件，同一目录下不允许有重名文件
  - 标识符：一个系统内的各文件标识符唯一，对用户来说毫无可读性，因此标识符只是操作系统用于区分各个文件的一种内部名称
  - 类型：指明文件的类型
  - 位置：文件存放的路径（让用户使用）、在外存中的地址（操作系统使用，对用户不可见
  - 大小：指明文件大小
  - 创建时间
  - 上次修改时间
  - 文件所有者信息
  - 保护信息：对文件进行保护的访问控制信息

### 文件内部的数据应该怎样组织起来？

- 无结构文件：如文本文件，由一些二进制或字符流，又称流式文件
- 有结构文件：如数据库，由一组相似的记录组成，又称记录式文件
  - 记录是一组相关数据项的集合
  - 数据项是文件系统中最基本的数据单位
  - 有结构文件中，各个记录之间应该如何组织？应该顺序存放？还是用索引表来记录记录之间的顺序？
    - 文件的逻辑结构

### 文件之间又应该怎么组织起来？

- 用户可以自己创建一层一层的目录，各层目录中存放相应的文件。系统中的各个文件就通过一层一层的目录合理有序地组织起来了
- 所谓的目录，就是我们所熟知的文件夹
- 目录也是一种特殊的有结构文件（由记录组成），如何实现文件目录是之后会重点探讨的问题

### 操作系统应该向上提供哪些功能

- 可以**创建文件**：点击新建后，图形化交换进程在背后调用了create系统调用
- 可以**读文件**：将文件数据读入内存，才能让CPU处理。双击后，记事本应用程序通过操作系统提供的读文件功能，即read系统调用，将文件数据从外存读入内存，并显示在屏幕上
- 可以**写文件**：将更改过的文件数据写回外存。我们在记事本应用程序中编辑文件内容，点击保存后，记事本应用程序通过操作系统提供的写文件功能，即write系统调用，将文件数据从内存写回外存
- 可以**删除文件**：点击删除之后，图形化交互进程通过操作系统提供的删除文件功能，即delete系统调用，将文件数据从外存中删除
- 打开文件（open系统调用）
- 关闭文件（close系统调用）

### 从上往下看，文件数据应该怎么存放在外存（磁盘）上

- 与内存一样，外存也是由一个个存储单元组成的，每个存储单元可以存储一定量的数据(如 1B)。每个存储单元对应一个物理地址
- 类似于内存分为一个个“内存块”外存会分为一个个“块/磁盘块/物理块”。每个磁盘块的大小是相等的，每块一般包含2的整数幂个地址（如本例中，一块包含2<sup>10</sup>个地址，即1KB）。同样类似的是，文件的逻辑地址也可以分为(逻辑块号，块内地址)，操作系统同样需要将逻辑地址转换为外存的物理地址（物理块号，块内地址）的形式。块内地址的位数取决于磁盘块的大小
- 操作系统以“块”为单位为文件分配存储空间，因此即使一个文件大小只有10B，但它依然需要占用 1KB 的磁盘块。外存中的数据读
  入内存时同样以块为单位
- 文件数据放在离散的几个磁盘块中。此时，应该如何记录各个磁盘块之间的先后顺序呢？
  - 文件的物理结构
- 操作系统又应该如何管理空闲磁盘块呢？

### 其他需要由操作系统实现的文件管理功能

- 文件共享：使多个用户可以共享使用一个文件
- 文件保护：如何保证不同的用户对文件有不同的操作权限
  - 之后会结合Windows操作系统的实际应用进行探讨

## （二）文件的逻辑结构

- 文件的逻辑结构
  - 无结构文件
  - 有结构文件
    - 顺序文件
    - 索引文件
    - 索引顺序文件
- 所谓的“逻辑结构”，就是指在用户看来，文件内部的数据应该是如何组织起来的。而“物理结构”指的是在操作系统看来，文件
  的数据是如何存放在外存中的。

### 无结构文件

- 按文件是否有结构分类，可以分为无结构文件、有结构文件两种。
- 无结构文件：文件内部的数据就是一系列二进制流或字符流组成。又称“流式文件”。如: Windows 操作系统中的.txt文件。

### 有结构文件

- 有结构文件：由一组相似的记录组成，又称‘记录式文件”。每条记录又若干个数据项组成。如：数据库表文件。一般来说，每条记录有一个数据项可作为关键字（作为识别不同记录的ID）。根据各条记录的长度（占用的存储空间）是否相等，又可分为定长记录和可变长记录两种
#### 顺序文件
- 顺序文件：文件中的记录一个接一个地顺序排列（逻辑上），记录可以是定长的或可变长的。各个记录在物理上可以顺序存储或链式存储
  - 顺序存储：逻辑上相邻的记录物理上也相邻
    - 两种结构：
      - 串结构：记录之间的顺序与关键字无关（通常按照记录存入的时间决定记录的顺序）
      - 顺序结构：记录之间按关键字顺序排列
    - 无论是定长/可变长记录，都无法实现随机存取，每次只能从第一个记录开始依次往后寻找
  - 链式存储：逻辑上相邻的记录物理上不一定相邻
    - 可变长记录：无法实现随机存取。每次只能从第一个记录开始依次往后查找
    - 定长记录：
      - 可实现随机存取。记录长度L，则第 i 个记录存放的相对位置是 i * L
      - 若采用串结构，无法快速找到某关键字对应的记录
      - 若采用顺序结构，可以快速找到某关键字对应的记录（如：折半查找）
- 结论：定长记录的顺序文件，若物理上采用顺序存储，则可实现随机存取；若能再保证记录的顺序结构，则可实现快速检索（即，根据关键字快速找到对应记录）
- 注：一般来说，考试题目中的“顺序文件”指的是物理上顺序存储的顺序文件

#### 索引文件

- 对于可变长记录文件，要找到第 i 个记录，必须先顺序查找前 i-1 个记录，但是很多应用场景中又必须使用可变长记录。如何解决？
  - 建立一张索引表以加快文件检索速度，每条记录对应一个索引项。文件中的这些记录在物理上可以离散地存放
- 索引表本身是定长及记录的顺序文件。因此可以快速找到第 i 个记录对应的索引项。可将关键字作为索引号内容，若按关键字顺序排列，则还可以支持按照关键字折半查找。
- 每当要增加/删除一个记录时，需要对索引表进行修改。由于索引文件有很快的检索速度，因此主要用于对信息处理的及时性要求比较高的场合。
- 另外，可以用不同的数据项建立多个索引表。如:学生信息表中，可用关键字“学号”建立一张索引表。也可用“姓名”建立一张索引表。这样就可以根据“姓名”快速地检索文件了。
  - Eg：SQL就支持根据某个数据项建立索引的功能

#### 索引顺序文件

- 思考索引文件的缺点:每个记录对应一个索引表项，因此索引表可能会很大。比如：文件的每个记录平均只占 8B，而每个索引表项占32个字节，那么索引表都要比文件内容本身大4倍，这样对存储者空间的利用率就太低了。
- 索引顺序文件是索引文件和顺序文件思想的结合。索引顺序文件中，同样会为文件建立一张索引表，但不同的是：并不是每个记录对应一个索引表项，而是一组记录对应一个索引表项。
- 学生记录按照学生姓名的开头字母进行分组。每个分组就是一个顺序文件，分组内的记录不需要按关键字排序
- 索引顺序文件的索引项也不需要按关键字顺序排列，这样可以极大地方便新表项的插入
- 用这种策略确实可以让索引表“瘦身”，但是是否会出现不定长记录的顺序文件检索速度慢的问题呢?
- 例：若一个顺序文件有10000个记录，则根据关键字检索文件，只能从头开始顺序查找（这里指的并不是定长记录、顺序结构的顺序文件），平均须查找5000 个记录。
  - 若采用索引顺序文件结构，可把10000个记录分为 100组，每组100个记录。则需要先顺序查找索引表找到分组（共100个分组，因此索引表长度为100，平均需要查50次），找到分组后，再在分组中顺序查找记录（每个分组100个记录，因此平均需要查50次）。可见，采用索引顺序文件结构后，平均查找次数减少为50+50=100次。
  - 同理，若文件有10<sup>6</sup>个记录，则可以分为1000个分组，每个分组1000个记录。根据关键字检索一个记录平均需要查找 500+500=1000次。这个查找次数依然很多，如何解决呢？
- 多级索引顺序文件：
  - 为了进一步提高检索效率，可以为顺序文件建立多级索引表。例如，对于一个含10<sup>6</sup>个记录的文件，可先为该文件建立一张低级索引表，每100个记录为一组，故低级索引表中共有10000个表项（即10000个定长记录），再把这10000个定长记录分组，每组100个，为其建立顶级索引表，故顶级索引表中共有100个表项。

## （三）文件目录

- 文件目录
  - 文件控制块（实现文件目录的关键数据结构）
  - 目录结构
    - 单级目录结构
    - 两级目录结构
    - 多级目录结构（树形目录结构）
    - 无环图目录结构
  - 索引结点（对文件控制块的优化）

### 文件控制块（FCB）

- 目录本身就是一种有结构文件，由一条条记录组成。每条记录对应一个放在该目录下的文件
- 目录文件中的一条记录就是一个文件控制块
- FCB的有序集称为文件目录，一个FCB就是一个文件目录项。
- FCB中包含了文件的
  - 基本信息（文件名、物理地址、逻辑地址、物理结构等）
  - 存取控制信息（是否可读/可写、禁止访问的用户名单等）
  - 使用信息（如：文件的建立时间、修改时间等）
- FCB实现了文件名和文件之间的映射。使用户（应用程序）可以实现按名存取
- 需要对文件目录进行哪些操作：
  - 搜索：当用户要使用一个文件时，系统要根据文件名搜索目录，找到该文件对应的目录项
  - 创建文件：创建一个新文件时，需要在其所属的目录中增加一个目录项
  - 删除文件：当删除一个文件时，需要在目录中删除相应的目录项
  - 显示目录：用户可以请求显示目录内容，如显示该目录中的所有文件及相应属性
  - 修改目录：某些文件属性保存在目录中，因此这些属性变化时需要修改相应的目录项（如：文件重命名）

### 目录结构：单级目录结构

- 早期操作系统并不支持多级目录，整个系统中只建立一张目录表，每个文件占一个目录项
- 单级目录实现了按名存取，但是不允许文件重名
- 在创建一个文件时，需要先检查目录表中有没有重名文件，确定不重名后才能允许建立文件，并将新文件对应的目录项插入目录表中
- 显然，单级目录结构不适用于多用户操作系统

### 目录结构：两级目录结构

- 早期的多用户操作系统，采用两级目录结构。分为主文件目录
